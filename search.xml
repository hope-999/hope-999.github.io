<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>No-150-fastapi中异步函数怎么测试</title>
    <url>/2025/08/09/No-150-fastapi%E4%B8%AD%E5%BC%82%E6%AD%A5%E5%87%BD%E6%95%B0%E6%80%8E%E4%B9%88%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[导读在 fastapi 中，经常会有异步函数，那么在测试的时候，怎么测试异步函数呢？
需要使用专门的工具和方法。pytest 通过 pytest-asyncio 插件提供了对异步测试的支持。
安装必要的包首先需要安装 pytest 和 pytest-asyncio：
pip install pytest pytest-asyncio

基本异步测试1. 简单异步测试import pytestasync def async_function():    return 42@pytest.mark.asyncioasync def test_async_function():    result = await async_function()    assert result == 42

2. 测试异步 HTTP 请求import pytestimport aiohttp@pytest.mark.asyncioasync def test_http_request():    async with aiohttp.ClientSession() as session:        async with session.get(&#x27;https://httpbin.org/get&#x27;) as resp:            assert resp.status == 200            data = await resp.json()            assert &#x27;url&#x27; in data

高级用法1. 使用异步 fixtureimport pytest@pytest.fixtureasync def async_fixture():    # 异步设置代码    yield &quot;fixture value&quot;    # 异步清理代码@pytest.mark.asyncioasync def test_with_async_fixture(async_fixture):    assert async_fixture == &quot;fixture value&quot;

2. 测试超时import pytestimport asyncioasync def slow_operation():    await asyncio.sleep(2)    return &quot;done&quot;@pytest.mark.asyncioasync def test_slow_operation():    with pytest.raises(asyncio.TimeoutError):        await asyncio.wait_for(slow_operation(), timeout=0.1)

3. 测试异步异常import pytestasync def async_raise_exception():    raise ValueError(&quot;Something went wrong&quot;)@pytest.mark.asyncioasync def test_async_exception():    with pytest.raises(ValueError, match=&quot;Something went wrong&quot;):        await async_raise_exception()

配置 pytest-asyncio可以在 pytest.ini 中配置 pytest-asyncio：
[pytest]asyncio_mode = auto

可选模式：

strict - 只运行标记为 @pytest.mark.asyncio 的测试
auto - 自动检测异步测试函数
legacy - 旧版行为

注意事项
确保测试函数被 @pytest.mark.asyncio 装饰
不要在同步函数中使用 await，这会导致语法错误
对于复杂的异步测试，考虑使用 asyncio 的事件循环控制
测试数据库操作时，确保使用支持异步的数据库驱动

完整示例# my_async_module.pyasync def fetch_data(db):    await db.connect()    data = await db.query(&quot;SELECT * FROM table&quot;)    return data# test_my_async_module.pyimport pytestfrom unittest.mock import AsyncMockfrom my_async_module import fetch_data@pytest.mark.asyncioasync def test_fetch_data():    # 创建异步mock对象    mock_db = AsyncMock()    mock_db.query.return_value = [1, 2, 3]        result = await fetch_data(mock_db)        assert result == [1, 2, 3]    mock_db.connect.assert_awaited_once()    mock_db.query.assert_awaited_once_with(&quot;SELECT * FROM table&quot;)

通过以上方法，你可以有效地测试 Python 中的异步代码。

每日踩一坑，生活更轻松。
本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。
]]></content>
  </entry>
  <entry>
    <title>No-149-fastapi中模型转json字符串的坑</title>
    <url>/2025/08/08/No-149-fastapi%E4%B8%AD%E6%A8%A1%E5%9E%8B%E8%BD%ACjson%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[导读在 fastapi 中，使用pydantic定义模型是非常简单的事情，可以让代码变得可读性更强。
在使用的时候经常遇到 模型 -&gt; json json -&gt; 模型 之间的转换。
在转换的时候遇到总报错，遂记录一下，谨记在心。
模型-&gt;json报错异常先写一段正常情况的测试代码，测试工具使用pytest：
from sqlmodel import Session, selectfrom app.core.db import db_enginefrom app.models.sqlmodel_table import EnvModeldef test_env_model():    with Session(db_engine) as session:        query = select(EnvModel).where(EnvModel.is_delete == 0)        result = session.exec(query).all()        print(result)

测试结果：
$ pytest -sv app/tests/scripts_service/env_model_test.pyapp/tests/scripts_service/env_model_test.py::test_env_model [EnvModel(case_env_id=&#x27;T12&#x27;, id=1, is_delete=0, updated_at=datetime.datetime(2025, 7, 10, 14, 42, 17), app_id=&#x27;&#x27;, case_env=&#x27;***内灰&#x27;, created_at=datetime.datetime(2025, 710, 14, 42, 17)), EnvModel(case_env_id=&#x27;T1760&#x27;, id=2, is_delete=0, updated_at=datetime.datetime(2025, 7, 10, 20, 3, 44), app_id=&#x27;app123456789abc&#x27;, case_env=&#x27;测试环境&#x27;, created_at=datetime.datetime(200, 14, 42, 17))]PASSED

模型转json错误用法1：使用 list 类型进行转换:
def test_env_model():    with Session(db_engine) as session:        query = select(EnvModel).where(EnvModel.is_delete == 0)        result = session.exec(query).all()        print(result.model_dump())

测试结果：
$ pytest -sv app/tests/scripts_service/env_model_test.pyFAILED app/tests/scripts_service/env_model_test.py::test_env_model - AttributeError: &#x27;list&#x27; object has no attribute &#x27;model_dump&#x27;

正确应该使用模型元素，而非列表：
def test_env_model():    with Session(db_engine) as session:        query = select(EnvModel).where(EnvModel.is_delete == 0)        result = session.exec(query).all()        for i in result:            print(i.model_dump())

测试结果：
$ pytest -sv app/tests/scripts_service/env_model_test.pyapp/tests/scripts_service/env_model_test.py::test_env_model &#123;&#x27;case_env_id&#x27;: &#x27;T12&#x27;, &#x27;is_delete&#x27;: 0, &#x27;case_env&#x27;: &#x27;***内灰&#x27;, &#x27;updated_at&#x27;: datetime.datetime(2025, 7, 10, 14, 42, 17), &#x27;id&#x27;: 1, &#x27;app_id&#x27;: &#x27;&#x27;, &#x27;created_at&#x27;: datetime.dateme(2025, 7, 10, 14, 42, 17)&#125;&#123;&#x27;case_env_id&#x27;: &#x27;T1760&#x27;, &#x27;is_delete&#x27;: 0, &#x27;case_env&#x27;: &#x27;测试环境&#x27;, &#x27;updated_at&#x27;: datetime.datetime(2025, 7, 10, 20, 3, 44), &#x27;id&#x27;: 2, &#x27;app_id&#x27;: &#x27;app123456789abc&#x27;, &#x27;created_at&#x27;: datetime.datetime(2025, 7, 42, 17)&#125;PASSED

可以看到，被转换成dict类型了，但是日期字段还是python类型。
打开model_dump()方法的源码看下：
def model_dump(    self,    *,    mode: Union[Literal[&quot;json&quot;, &quot;python&quot;], str] = &quot;python&quot;,    include: Union[IncEx, None] = None,    exclude: Union[IncEx, None] = None,    context: Union[Dict[str, Any], None] = None,    by_alias: bool = False,    exclude_unset: bool = False,    exclude_defaults: bool = False,    exclude_none: bool = False,    round_trip: bool = False,    warnings: Union[bool, Literal[&quot;none&quot;, &quot;warn&quot;, &quot;error&quot;]] = True,    serialize_as_any: bool = False,) -&gt; Dict[str, Any]:    if PYDANTIC_MINOR_VERSION &gt;= (2, 7):        extra_kwargs: Dict[str, Any] = &#123;            &quot;context&quot;: context,            &quot;serialize_as_any&quot;: serialize_as_any,        &#125;    else:        extra_kwargs = &#123;&#125;    if IS_PYDANTIC_V2:        return super().model_dump(            mode=mode,            include=include,            exclude=exclude,            by_alias=by_alias,            exclude_unset=exclude_unset,            exclude_defaults=exclude_defaults,            exclude_none=exclude_none,            round_trip=round_trip,            warnings=warnings,            **extra_kwargs,        )    else:        return super().dict(            include=include,            exclude=exclude,            by_alias=by_alias,            exclude_unset=exclude_unset,            exclude_defaults=exclude_defaults,            exclude_none=exclude_none,        )

可以看到，默认的模式就是 python。
当我们把 mode 赋值成 json 看看。
def test_env_model():    with Session(db_engine) as session:        query = select(EnvModel).where(EnvModel.is_delete == 0)        result = session.exec(query).all()        for i in result:            print(i.model_dump(mode=&quot;json&quot;))

测试结果：
$ pytest -sv app/tests/scripts_service/env_model_test.pyapp/tests/scripts_service/env_model_test.py::test_env_model &#123;&#x27;case_env_id&#x27;: &#x27;T12&#x27;, &#x27;is_delete&#x27;: 0, &#x27;id&#x27;: 1, &#x27;updated_at&#x27;: &#x27;2025-07-10T14:42:17&#x27;, &#x27;app_id&#x27;: &#x27;&#x27;, &#x27;case_env&#x27;: &#x27;***内灰&#x27;, &#x27;created_at&#x27;: &#x27;2025-07-10T14:42:17&#x27;&#125;&#123;&#x27;case_env_id&#x27;: &#x27;T1760&#x27;, &#x27;is_delete&#x27;: 0, &#x27;id&#x27;: 2, &#x27;updated_at&#x27;: &#x27;2025-07-10T20:03:44&#x27;, &#x27;app_id&#x27;: &#x27;app123456789abc&#x27;, &#x27;case_env&#x27;: &#x27;测试环境&#x27;, &#x27;created_at&#x27;: &#x27;2025-07-10T14:42:17&#x27;&#125;PASSED

这下就是比较正常的数据了。
总结当使用 model_dump() 进行模型转换时需要注意：

要转换的类型需要是模型实例，而非 list
需要指定 mode=&quot;json&quot;，否则日期格式无法正确转换


每日踩一坑，生活更轻松。
本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。
]]></content>
  </entry>
  <entry>
    <title>No-152-fastapi中如何写webhook接口</title>
    <url>/2025/08/11/No-152-fastapi%E4%B8%AD%E5%A6%82%E4%BD%95%E5%86%99webhook%E6%8E%A5%E5%8F%A3/</url>
    <content><![CDATA[导读在构建 CICD 的过程中，经常会用到一些工具，比如：Jenkins、GitLab、Coding 等。
这些构建工具都有一个共同点：它们能支持 webHook 的触发。
比如 gitlib 中设置当前 push 代码的时候触发 webhook。
当我们配置了 webhook 以后，会在触发事件发生的时候，去请求一个自定义的 url。
这样就丰富了我们在构建 CICD 的流程中，去处理更多的业务逻辑。
webhook 如何自定义接口@router.post(&quot;/webhook/1.0.0&quot;, name=&quot;webhook&quot;)async def add_new(    request: Request,) -&gt; Any:    # 解析 Webhook 请求体的 JSON 数据    body = await request.body()    # 解析 JSON 数据    try:        data = json.loads(body.decode(&quot;utf-8&quot;))    except json.JSONDecodeError:        return Response(&quot;ok&quot;)    logger.info(f&quot;webhook的body=&#123;data&#125;&quot;)    # 这里添加业务逻辑    # ...    return Response(&quot;ok&quot;)

说明
请求方法定义为 post，一般要使用post方法。
设置请求类型为 application&#x2F;json
读取请求数据，并解析。body = await request.body()
读取 json 数据,data = json.loads(body.decode(&quot;utf-8&quot;))，这里要注意异常的捕获，防止报错。
在处理逻辑中，一般需要进行数据校验，避免接口报错。
在需要使用日志信息时，要添加 logger。
解析 body 中的参数。
添加业务处理逻辑。
返回 ok, 返回 ok 告诉 webhook 通知发送端，接口正常处理完成。这里要记住一定要返回 ok，否则会不停的触发事件。return Response(&quot;ok&quot;)

如何测试？使用 curl 的 post 方式，带上 body 数据，示例：
curl --location --request POST &#x27;http://127.0.0.1:9000/webhook/1.0.0&#x27; \--header &#x27;Content-Type: application/json&#x27; \--data-raw &#x27;&#123;&quot;object_kind&quot;: &quot;deployment&quot;, &quot;id&quot;: 123&#125;&#x27;


每日踩一坑，生活更轻松。
本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。
]]></content>
  </entry>
  <entry>
    <title>No-153-fastapi中使用redis-pool连接池</title>
    <url>/2025/08/12/No-153-fastapi%E4%B8%AD%E4%BD%BF%E7%94%A8redispool%E8%BF%9E%E6%8E%A5%E6%B1%A0/</url>
    <content><![CDATA[导读在实际开发过程中，为了提升接口性能，我们经常会选择使用数据库连接池、redis 连接池等。
通过连接池连接，提升效率，节省内存开销。同时通过将数据缓存到 redis 中，还可以减少网络 IO 开销。
通常一个接口直接跟数据库交互，例如 MySQL，响应时间大概在 200ms ~ 500ms 左右。加上 redis 缓存之后，接口直接从缓存中读取，响应时间可以缩短到 10ms 左右，可以说是质的飞跃。
下面将介绍如何在 FastAPI 中使用 redis 连接池。
1、安装库首先确保安装了必要的 Python 包：
pip install fastapi redis uvicorn

2. 添加配置在根目录下，添加 .env.dev 文件，里面是项目相关配置。
REDIS_HOST=&quot;192.168.201.200&quot;REDIS_PORT=&quot;6379&quot;REDIS_PASSWORD=&quot;&lt;PASSWORD&gt;&quot;REDIS_DB=&quot;9&quot;

在 config.py 文件中，增加如下代码，读取配置信息。
import osfrom typing import Annotated, Anyfrom pydantic import (    AnyUrl,    BeforeValidator,    PostgresDsn,    computed_field,)from pydantic_core import MultiHostUrlfrom pydantic_settings import BaseSettings, SettingsConfigDictclass Settings(BaseSettings):    if os.getenv(&quot;APP_ENV&quot;) == &quot;development&quot; or not os.getenv(&quot;APP_ENV&quot;):            model_config = SettingsConfigDict(                env_file=&quot;.env.dev&quot;, env_ignore_empty=True, extra=&quot;ignore&quot;            )    if os.getenv(&quot;APP_ENV&quot;) == &quot;production&quot;:        model_config = SettingsConfigDict(            env_file=&quot;/app/.env.production&quot;, env_ignore_empty=True, extra=&quot;ignore&quot;        )    if os.getenv(&quot;APP_ENV&quot;) == &quot;test&quot;:        model_config = SettingsConfigDict(            env_file=&quot;.env.test&quot;, env_ignore_empty=True, extra=&quot;ignore&quot;        )    REDIS_HOST: str    REDIS_PORT: int     REDIS_PASSWD: str     REDIS_DB: intsettings = Settings()

3. 添加 redis 连接池在 db.py 中，创建 redis 连接池。
from config import settingsimport redisfrom fastapi import Depends# 创建 Redis 连接池redis_pool = redis.ConnectionPool(    host=settings.REDIS_HOST,    port=settings.REDIS_PORT,    db=settings.REDIS_DB,    decode_responses=True,  # 自动解码返回的字节为字符串    max_connections=10     # 最大连接数)

4. 创建deps在 deps.py 文件中，定义一个依赖项。
import redisfrom logger import loggerdef get_redis():    &quot;&quot;&quot;获取 Redis 连接的依赖函数&quot;&quot;&quot;    try:        redis_conn = redis.Redis(connection_pool=redis_pool)        yield redis_conn    except Exception as e:        # 可选择加入日志记录或错误上报        logger.exception(f&quot;Error occurred while managing redis pool session: &#123;e&#125;&quot;)        raise    finally:        # 这里不需要手动关闭连接，连接会返回到连接池中        passRedisPoolDep = Annotated[Redis, Depends(get_redis)]

5. 使用 RedisPoolDep 依赖项在你的主应用文件（如 main.py）中使用这个连接池：
from fastapi import FastAPI, Dependsfrom deps import RedisPoolDepimport redisapp = FastAPI()@app.get(&quot;/set/&#123;key&#125;/&#123;value&#125;&quot;)async def set_key_value(    key: str,     value: str,     redis_conn: RedisPoolDep):    &quot;&quot;&quot;设置键值对&quot;&quot;&quot;    redis_conn.set(key, value)    return &#123;&quot;message&quot;: f&quot;Set &#123;key&#125; = &#123;value&#125;&quot;&#125;@app.get(&quot;/get/&#123;key&#125;&quot;)async def get_key(    key: str,     redis_conn: RedisPoolDep):    &quot;&quot;&quot;获取键值&quot;&quot;&quot;    value = redis_conn.get(key)    return &#123;&quot;key&quot;: key, &quot;value&quot;: value&#125;@app.get(&quot;/info&quot;)async def redis_info(redis_conn: RedisPoolDep):    &quot;&quot;&quot;获取 Redis 服务器信息&quot;&quot;&quot;    info = redis_conn.info()    return &#123;&quot;redis_info&quot;: info&#125;

总结
创建 Redis 连接池并在应用启动时初始化
创建依赖函数 get_redis() 来获取连接
在路由处理函数中使用 Depends(get_redis) 注入 Redis 连接
对于更复杂的应用，将业务逻辑封装到服务层
考虑使用异步 Redis 客户端以提高性能, 例如 aioredis。这里有坑，慎用。。。
使用环境变量管理配置


每日踩一坑，生活更轻松。
本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。
]]></content>
  </entry>
  <entry>
    <title>No-151-fastapi中批量更新数据怎么保证数据的一致性</title>
    <url>/2025/08/10/No-151-fastapi%E4%B8%AD%E6%89%B9%E9%87%8F%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</url>
    <content><![CDATA[导读在 fastapi 中，API 最常见的情况是批量更新数据，一个逻辑层的函数可能包含多次数据库交互，有新增数据、更新数据逻辑，那么在保证数据的一致性方面应该怎么做呢？
下面我将详细说明在 FastAPI 中实现批量更新的两种主要方式，并提供完整的代码示例。
1. 使用数据库事务实现批量更新这种方式通过数据库事务保证所有更新操作要么全部成功，要么全部失败。
完整示例代码from fastapi import FastAPI, HTTPException, Dependsfrom pydantic import BaseModelfrom typing import Listfrom sqlalchemy import create_engine, Column, Integer, Stringfrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, Session# 数据库配置SQLALCHEMY_DATABASE_URL = &quot;sqlite:///./test.db&quot;engine = create_engine(SQLALCHEMY_DATABASE_URL)SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)Base = declarative_base()# 数据库模型class User(Base):    __tablename__ = &quot;users&quot;    id = Column(Integer, primary_key=True, index=True)    name = Column(String(50))    email = Column(String(50))    status = Column(String(20))# 创建表Base.metadata.create_all(bind=engine)# Pydantic 模型class UserUpdate(BaseModel):    id: int    name: str = None    email: str = None    status: str = Noneapp = FastAPI()# 依赖项 - 获取数据库会话def get_db():    db = SessionLocal()    try:        yield db    finally:        db.close()@app.put(&quot;/users/bulk-update-transaction&quot;)async def bulk_update_users_transaction(    users: List[UserUpdate],     db: Session = Depends(get_db)):    try:        # 开始事务        db.begin()                for user_data in users:            # 查询用户            user = db.query(User).filter(User.id == user_data.id).first()            if not user:                raise HTTPException(status_code=404, detail=f&quot;User with id &#123;user_data.id&#125; not found&quot;)                        # 更新字段            if user_data.name is not None:                user.name = user_data.name            if user_data.email is not None:                user.email = user_data.email            if user_data.status is not None:                user.status = user_data.status                        # 也可以使用 merge 方法            # db.merge(user)                # 提交事务        db.commit()    except HTTPException:        # 已知异常直接抛出        db.rollback()        raise    except Exception as e:        # 其他异常回滚并返回错误        db.rollback()        raise HTTPException(status_code=500, detail=str(e))        return &#123;&quot;message&quot;: &quot;Batch update completed successfully&quot;, &quot;updated_count&quot;: len(users)&#125;

关键点说明
事务管理：

db.begin() 显式开始事务
db.commit() 提交事务
db.rollback() 在异常时回滚


错误处理：

处理了用户不存在的场景
捕获所有异常确保事务回滚
返回适当的HTTP状态码


原子性保证：

所有更新要么全部成功，要么全部失败
中间出错不会导致部分更新



2. 使用批量操作语句实现批量更新这种方式通过单个SQL语句执行批量更新，效率更高。
完整示例代码2from sqlalchemy import update, bindparam@app.put(&quot;/users/bulk-update-bulk-statement&quot;)async def bulk_update_users_bulk_statement(    users: List[UserUpdate],     db: Session = Depends(get_db)):    try:        # 构建批量更新语句        stmt = (            update(User)            .where(User.id == bindparam(&#x27;user_id&#x27;))            .values(&#123;                User.name: bindparam(&#x27;user_name&#x27;),                User.email: bindparam(&#x27;user_email&#x27;),                User.status: bindparam(&#x27;user_status&#x27;)            &#125;)        )                # 准备参数列表        params = []        for user in users:            param = &#123;                &#x27;user_id&#x27;: user.id,                &#x27;user_name&#x27;: user.name,                &#x27;user_email&#x27;: user.email,                &#x27;user_status&#x27;: user.status            &#125;            params.append(param)                # 执行批量更新        result = db.execute(stmt, params)        db.commit()                # 返回更新的行数        updated_count = result.rowcount            except Exception as e:        db.rollback()        raise HTTPException(status_code=500, detail=str(e))        return &#123;        &quot;message&quot;: &quot;Batch update completed with bulk statement&quot;,        &quot;updated_count&quot;: updated_count    &#125;

关键点说明2
批量SQL构建：

使用 update() 和 bindparam() 构建参数化查询
单个SQL语句处理所有更新


参数准备：

将输入数据转换为参数列表
每个参数对应一个字典


执行效率：

相比循环更新，减少数据库往返次数
数据库可以优化执行计划


返回值：

通过 result.rowcount 获取实际更新的行数



两种方式的比较


特性
事务方式
批量语句方式



实现复杂度
简单直接
需要构建SQL语句


性能
中等（多次数据库调用）
高（单次数据库调用）


灵活性
高（可处理复杂逻辑）
中（适合简单字段更新）


错误处理
可以逐条检查
批量处理，难以单独处理某条失败


适用场景
需要复杂逻辑或验证的更新
大批量简单字段更新


测试示例你可以使用这样的请求体测试上述API：
[    &#123;        &quot;id&quot;: 1,        &quot;name&quot;: &quot;New Name 1&quot;,        &quot;email&quot;: &quot;new1@example.com&quot;,        &quot;status&quot;: &quot;active&quot;    &#125;,    &#123;        &quot;id&quot;: 2,        &quot;name&quot;: &quot;New Name 2&quot;,        &quot;email&quot;: &quot;new2@example.com&quot;,        &quot;status&quot;: &quot;inactive&quot;    &#125;]

实际业务中，根据你的具体需求选择合适的实现方式。

对于需要复杂业务逻辑的更新，事务方式更合适；
对于纯粹的大批量数据更新，批量语句方式性能更好。

总之：在一个逻辑函数中处理事务，避免中间状态，确保原子性和一致性，尽量不要写一段逻辑提交一次，而是在逻辑函数结束时候提交或回滚一次。如果遇到高并发场景，还需要考虑锁策略。

每日踩一坑，生活更轻松。
本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。
]]></content>
  </entry>
</search>
