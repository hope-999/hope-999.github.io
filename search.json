[{"title":"No.147-Python生成不重复的分支名","url":"/2025/08/14/No-147-Python%E7%94%9F%E6%88%90%E4%B8%8D%E9%87%8D%E5%A4%8D%E7%9A%84%E5%88%86%E6%94%AF%E5%90%8D/","content":"导读在开发过程中，经常遇到一些名称需要自动化生成，并且名称要求唯一性。这就要求名称随时生成，并且跟前面的名称不重复。\n例如：任务id、分支id 等\n项目开发中实际上用到了生成分支名称的场景。\n介绍四种方法方法1: 使用时间戳 + 随机字符串（推荐）import timeimport randomimport stringdef generate_branch_name(prefix=&quot;feature&quot;):    timestamp = int(time.time() * 1000)    random_str = &#x27;&#x27;.join(random.choices(string.ascii_lowercase + string.digits, k=4))    return f&quot;&#123;prefix&#125;-&#123;timestamp&#125;-&#123;random_str&#125;&quot;# 示例使用print(generate_branch_name())  # 例如: feature-1751283975396-ab3dprint(generate_branch_name(&quot;bugfix&quot;))  # 例如: bugfix-1751283983855-c4e2\n\n这种方法唯一的缺点就是：并发非常高的时候，会重复。一般情况下足够了。\n方法2: 使用UUID（推荐）import uuiddef generate_branch_name(prefix=&quot;feature&quot;):    unique_id = str(uuid.uuid4())    return f&quot;&#123;prefix&#125;-&#123;unique_id&#125;&quot;# 示例使用print(generate_branch_name())  # 例如: feature-65317f15-65a8-47ea-8b5b-380c738015e0\n\n这种方式会重复吗？\nUUID v4生成规则：基于随机数生成。\n重复概率：约 1&#x2F;2^122（即约 5.3×10⁻³⁶）。\n举例：每秒生成 10 亿个 UUID，持续约 85 年 才有 50% 的概率发生一次重复。\n所以重复的概率极低。\n方法3: 基于用户和项目信息（推荐）import getpassimport timeimport hashlibdef generate_branch_name(prefix=&quot;feature&quot;, project_name=None):    user = getpass.getuser()    timestamp = int(time.time())        if project_name:        base_str = f&quot;&#123;user&#125;-&#123;project_name&#125;-&#123;timestamp&#125;&quot;    else:        base_str = f&quot;&#123;user&#125;-&#123;timestamp&#125;&quot;        # 使用hash缩短    hash_str = hashlib.md5(base_str.encode()).hexdigest()    return f&quot;&#123;prefix&#125;-&#123;hash_str&#125;&quot;# 示例使用print(generate_branch_name())  # 例如: feature-81bbf63af6cba2da8541d72c8c02fd60print(generate_branch_name(project_name=&quot;myproject&quot;))  # 例如: feature-ba34657bd9983d679d00a7d991d333ba\n\n方法4: 使用递增计数器（需要存储）(不推荐)import osdef generate_branch_name(prefix=&quot;feature&quot;):    counter_file = &quot;.branch_counter&quot;        # 读取或初始化计数器    if os.path.exists(counter_file):        with open(counter_file, &quot;r&quot;) as f:            counter = int(f.read()) + 1    else:        counter = 1        # 保存新计数器值    with open(counter_file, &quot;w&quot;) as f:        f.write(str(counter))        return f&quot;&#123;prefix&#125;-&#123;counter:04d&#125;&quot;# 示例使用print(generate_branch_name())  # 例如: feature-0001, feature-0002 等\n\n这种方式比较简单，适合并发不高的场景，一般不推荐。\n选择哪种方法取决于你的具体需求：\n\n如果只需要简单唯一性，方法1或2足够\n如果需要可读性，方法3不错\n如果需要顺序编号，使用方法4\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.148-fastapi中使用标准化出入参自动化生成接口文档","url":"/2025/08/07/No-148-fastapi%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%A0%87%E5%87%86%E5%8C%96%E5%87%BA%E5%85%A5%E5%8F%82%E8%87%AA%E5%8A%A8%E5%8C%96%E7%94%9F%E6%88%90%E6%8E%A5%E5%8F%A3%E6%96%87%E6%A1%A3/","content":"导读在 fastapi 中，自动化生成文档是一个非常简单的事情。\n但是也需要遵循一些非常必要的规则来帮助我们更好的生成便于阅读的文档。\n这篇文章将介绍从入参的定义、到返回结构体的定义，异常捕获几个方面来规范接口开发文档。\n使用的参数校验库为：pydantic。\n入参的定义必填参数from typing import Optional, List, Literal, Unionfrom pydantic import BaseModel, Fieldclass RemoveModuleRequest(BaseModel):    service_id: int = Field(..., description=&quot;服务 id&quot;)\n\n说明：\n\n定义 class 类\n继承 BaseModel\n使用 Field 定义参数类型等。\n这里定义了service_id字段为int类型\nField 第一个参数的默认值为 ...，就表示是必填参数\n\n非必填参数from typing import Optional, List, Literal, Unionfrom pydantic import BaseModel, Fieldclass ModuleCaseManagerCaseListRequest(BaseModel):    order_id: Optional[int] = Field(default=None, description=&quot;工单id&quot;)\n\n说明：\n\n这里定义了order_id字段为int类型\n使用 Optional 包裹住 int 表示非必填\n结合Field 第一个参数的默认值为 default=None，就表示是非必填参数\n\n注意：这里的 default=None 不能简写成 None，简写之后文档将识别不了，不知道这个问题 fastapi 官方修复了没。\n字符串参数长度定义from typing import Optional, List, Literal, Unionfrom pydantic import BaseModel, Fieldclass ModuleCaseManagerCaseListRequest(BaseModel):    env_id: Optional[str] = Field(default=None, max_length=8, min_length=4, description=&quot;工单id&quot;)\n\n说明：\n\n这里定义了env_id字段为str类型\n使用 Optional 包裹住 str 表示非必填\n结合Field 第一个参数的默认值为 default=None，就表示是非必填参数\nmax_length 定义字段最长为 8 个字符\nmin_length 定义字段最短为 4 个字符\n\n参数可选值class RequestEnv(BaseModel):    env: Literal[&quot;dev&quot;, &quot;test&quot;, &quot;pro&quot;] = Field(        ..., description=&quot;环境: dev-开发, test-测试, pro-现网&quot;    )\n\n说明：\n\nLiteral[&quot;dev&quot;, &quot;test&quot;, &quot;pro&quot;] 定义可选值\n\n嵌套参数以上处理的都是层级比较单一的入参例如格式这样的:\n &#123;    &quot;service&quot;: &quot;&quot;,    &quot;plan_id&quot;: &quot;0&quot;,    &quot;order_id&quot;: &quot;0&quot;,    &quot;env_id&quot;: &quot;&quot;&#125;\n\n如果要处理多个层级的入参，例如这样的参数怎么处理:\n  &#123;    &quot;services&quot;: [&#123;        &quot;service_type&quot;: &quot;&quot;,        &quot;service_info_id&quot;: 0,        &quot;branch_id&quot;: 0,        &quot;api_ids&quot;: [101, 201, 345]    &#125;],    &quot;plan_id&quot;: &quot;0&quot;,    &quot;order_id&quot;: &quot;0&quot;,    &quot;env_id&quot;: &quot;&quot;&#125;\n\n 只需要再定义一个模型，进行嵌套即可：\n class ApiCaseManagerRunCaseServiceData(BaseModel):    service_type: str = Field(..., description=&quot;服务类型&quot;)    service_info_id: int = Field(..., description=&quot;服务id&quot;)    branch_id: int = Field(..., description=&quot;分支id&quot;)    api_ids: list = Field(..., description=&quot;接口id列表&quot;, example=[101, 201, 345])class ApiCaseManagerRunCaseRequest(BaseModel):    services: List[ApiCaseManagerRunCaseServiceData] = Field(..., description=&quot;服务列表&quot;) # 这里嵌套模型    plan_id: Optional[int] = Field(default=0, description=&quot;计划 ID，关联业务计划的标识&quot;)    order_id: Optional[int] = Field(default=0, description=&quot;工单id&quot;)    env_id: str = Field(..., description=&quot;环境id&quot;)\n\n返回结构体定义基础结构体的定义T = TypeVar(&quot;T&quot;)  # 泛型类型变量，用于data字段class BaseResponse(BaseModel, Generic[T]):    &quot;&quot;&quot;    基础响应模型，所有API响应都应继承此模型    &quot;&quot;&quot;    code: int = Field(default=0, description=&quot;状态码，0表示成功，非0表示错误&quot;, example=0)    rec_ts: float = Field(        ...,        description=&quot;请求接收时间戳（Unix时间戳，精确到毫秒）&quot;,        example=1611399999.999999,    )    rsp_ts: float = Field(        ...,        description=&quot;响应生成时间戳（Unix时间戳，精确到毫秒）&quot;,        example=1611399999.999999,    )    msg: str = Field(        default=&quot;success&quot;,        description=&quot;状态消息，成功时为&#x27;success&#x27;，错误时为错误描述&quot;,        example=&quot;success&quot;,    )    data: Optional[T] = Field(default=None, description=&quot;实际返回的数据内容，错误时为null&quot;)    @classmethod    def success(cls, data: T = None, msg: str = &quot;success&quot;):        &quot;&quot;&quot;成功的快捷方法&quot;&quot;&quot;        now = datetime.now().timestamp()        return cls(code=0, rec_ts=now, rsp_ts=now, msg=msg, data=data)\n\n定义要返回的数据模型class PeopleDataModel(BaseModel):    numbers: List[int]    people: List[str]class PeopleDataModelResponse(BaseResponse[PeopleDataModel]):    pass\n\n路由函数中使用@router.post(&quot;/case_list/1.0.0&quot;, response_model=PeopleDataModelResponse, name=&quot;用例列表&quot;)def case_list(    db_session: DbSessionDep    request: ApiCaseManagerCaseListRequest) -&gt; Any:    &quot;&quot;&quot;用例列表    Args:        db_session: 数据库连接        request: 请求参数    Returns:        Any    &quot;&quot;&quot;    # 获取查询结果（列表）    data = case_list_crud(request, db_session)    return PeopleDataModelResponse.success(data=data)\n\n返回数据格式示例&#123;  &quot;code&quot;: 0,  &quot;rec_ts&quot;: 1611399999.999999,  &quot;rsp_ts&quot;: 1611399999.999999,  &quot;msg&quot;: &quot;success&quot;,  &quot;data&quot;:&#123;      &quot;numbers&quot;: 0,      &quot;people&quot;: &quot; 小明&quot;    &#125;&#125;\n\n也可以不用定义PeopleDataModelResponse@router.post(&quot;/case_list/1.0.0&quot;, response_model=BaseResponse[PeopleDataModel], name=&quot;用例列表&quot;)def case_list(    db_session: DbSessionDep    request: ApiCaseManagerCaseListRequest) -&gt; Any:    &quot;&quot;&quot;用例列表    Args:        db_session: 数据库连接        request: 请求参数    Returns:        Any    &quot;&quot;&quot;    # 获取查询结果（列表）    data = case_list_crud(request, db_session)    return BaseResponse[PeopleDataModel].success(data=data)\n\n如果返回的数据data是列表from typing import List@router.post(&quot;/case_list/1.0.0&quot;, response_model=BaseResponse[List[PeopleDataModel]], name=&quot;用例列表&quot;)def case_list(    db_session: DbSessionDep    request: ApiCaseManagerCaseListRequest) -&gt; Any:    &quot;&quot;&quot;用例列表    Args:        db_session: 数据库连接        request: 请求参数    Returns:        Any    &quot;&quot;&quot;    # 获取查询结果（列表）    data = case_list_crud(request, db_session) # 返回的列表中数据的类型是 PeopleDataModel    return BaseResponse[List[PeopleDataModel]].success(data=data)\n\n返回数据格式示例&#123;  &quot;code&quot;: 0,  &quot;rec_ts&quot;: 1611399999.999999,  &quot;rsp_ts&quot;: 1611399999.999999,  &quot;msg&quot;: &quot;success&quot;,  &quot;data&quot;:[    &#123;    &quot;numbers&quot;: 0,    &quot;people&quot;: &quot; 小明&quot;    &#125;,    &#123;    &quot;numbers&quot;: 2,    &quot;people&quot;: &quot; 小蘑菇&quot;    &#125;  ]&#125;\n\n返回体结构灵感来源：https://docs.pydantic.dev/2.8/concepts/models/#generic-models 中的 Generic models 章节。\n异常捕获定义异常类class ResponseErrorV2(Exception):    def __init__(self, status_code: int, code: int, msg: str):        self.status_code = status_code        self.code = code        self.msg = msg\n\nfastapi捕获异常main.py 入口函数：\n@app.exception_handler(ResponseErrorV2)async def custom_error_handler(request: Request, exc: ResponseErrorV2):    return JSONResponse(        status_code=exc.status_code,        content=&#123;&quot;code&quot;: exc.code, &quot;msg&quot;: exc.msg&#125;,    )\n\n主动抛异常raise ResponseErrorV2(status_code=400, code=400001, msg=&quot;请求头必须携带Token&quot;)\n\n接口返回数据结构status: 400\n&#123;  &quot;code&quot;: 400001,  &quot;msg&quot;: &quot;请求头必须携带Token&quot;&#125;\n\n\n生成文档启动fastapi服务，编写shell脚本：generate_swagger.sh\n#! /bin/bashcurl -X GET http://127.0.0.1:9000/openapi.json &gt; docs/api/swagger.json\n\n分别执行如下命令：\nchmod +x generate_swagger.sh./generate_swagger.sh\n\n总结pydantic 不仅可以在编写代码的过程中规范书写格式，还能自动化生成文档，还可以帮我们校验出入参的格式，让代码的可读性进一步加强。\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.149-fastapi中模型转json字符串的坑","url":"/2025/08/08/No-149-fastapi%E4%B8%AD%E6%A8%A1%E5%9E%8B%E8%BD%ACjson%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%9D%91/","content":"导读在 fastapi 中，使用pydantic定义模型是非常简单的事情，可以让代码变得可读性更强。\n在使用的时候经常遇到 模型 -&gt; json json -&gt; 模型 之间的转换。\n在转换的时候遇到总报错，遂记录一下，谨记在心。\n模型-&gt;json报错异常先写一段正常情况的测试代码，测试工具使用pytest：\nfrom sqlmodel import Session, selectfrom app.core.db import db_enginefrom app.models.sqlmodel_table import EnvModeldef test_env_model():    with Session(db_engine) as session:        query = select(EnvModel).where(EnvModel.is_delete == 0)        result = session.exec(query).all()        print(result)\n\n测试结果：\n$ pytest -sv app/tests/scripts_service/env_model_test.pyapp/tests/scripts_service/env_model_test.py::test_env_model [EnvModel(case_env_id=&#x27;T12&#x27;, id=1, is_delete=0, updated_at=datetime.datetime(2025, 7, 10, 14, 42, 17), app_id=&#x27;&#x27;, case_env=&#x27;***内灰&#x27;, created_at=datetime.datetime(2025, 710, 14, 42, 17)), EnvModel(case_env_id=&#x27;T1760&#x27;, id=2, is_delete=0, updated_at=datetime.datetime(2025, 7, 10, 20, 3, 44), app_id=&#x27;app123456789abc&#x27;, case_env=&#x27;测试环境&#x27;, created_at=datetime.datetime(200, 14, 42, 17))]PASSED\n\n模型转json错误用法1：使用 list 类型进行转换:\ndef test_env_model():    with Session(db_engine) as session:        query = select(EnvModel).where(EnvModel.is_delete == 0)        result = session.exec(query).all()        print(result.model_dump())\n\n测试结果：\n$ pytest -sv app/tests/scripts_service/env_model_test.pyFAILED app/tests/scripts_service/env_model_test.py::test_env_model - AttributeError: &#x27;list&#x27; object has no attribute &#x27;model_dump&#x27;\n\n正确应该使用模型元素，而非列表：\ndef test_env_model():    with Session(db_engine) as session:        query = select(EnvModel).where(EnvModel.is_delete == 0)        result = session.exec(query).all()        for i in result:            print(i.model_dump())\n\n测试结果：\n$ pytest -sv app/tests/scripts_service/env_model_test.pyapp/tests/scripts_service/env_model_test.py::test_env_model &#123;&#x27;case_env_id&#x27;: &#x27;T12&#x27;, &#x27;is_delete&#x27;: 0, &#x27;case_env&#x27;: &#x27;***内灰&#x27;, &#x27;updated_at&#x27;: datetime.datetime(2025, 7, 10, 14, 42, 17), &#x27;id&#x27;: 1, &#x27;app_id&#x27;: &#x27;&#x27;, &#x27;created_at&#x27;: datetime.dateme(2025, 7, 10, 14, 42, 17)&#125;&#123;&#x27;case_env_id&#x27;: &#x27;T1760&#x27;, &#x27;is_delete&#x27;: 0, &#x27;case_env&#x27;: &#x27;测试环境&#x27;, &#x27;updated_at&#x27;: datetime.datetime(2025, 7, 10, 20, 3, 44), &#x27;id&#x27;: 2, &#x27;app_id&#x27;: &#x27;app123456789abc&#x27;, &#x27;created_at&#x27;: datetime.datetime(2025, 7, 42, 17)&#125;PASSED\n\n可以看到，被转换成dict类型了，但是日期字段还是python类型。\n打开model_dump()方法的源码看下：\ndef model_dump(    self,    *,    mode: Union[Literal[&quot;json&quot;, &quot;python&quot;], str] = &quot;python&quot;,    include: Union[IncEx, None] = None,    exclude: Union[IncEx, None] = None,    context: Union[Dict[str, Any], None] = None,    by_alias: bool = False,    exclude_unset: bool = False,    exclude_defaults: bool = False,    exclude_none: bool = False,    round_trip: bool = False,    warnings: Union[bool, Literal[&quot;none&quot;, &quot;warn&quot;, &quot;error&quot;]] = True,    serialize_as_any: bool = False,) -&gt; Dict[str, Any]:    if PYDANTIC_MINOR_VERSION &gt;= (2, 7):        extra_kwargs: Dict[str, Any] = &#123;            &quot;context&quot;: context,            &quot;serialize_as_any&quot;: serialize_as_any,        &#125;    else:        extra_kwargs = &#123;&#125;    if IS_PYDANTIC_V2:        return super().model_dump(            mode=mode,            include=include,            exclude=exclude,            by_alias=by_alias,            exclude_unset=exclude_unset,            exclude_defaults=exclude_defaults,            exclude_none=exclude_none,            round_trip=round_trip,            warnings=warnings,            **extra_kwargs,        )    else:        return super().dict(            include=include,            exclude=exclude,            by_alias=by_alias,            exclude_unset=exclude_unset,            exclude_defaults=exclude_defaults,            exclude_none=exclude_none,        )\n\n可以看到，默认的模式就是 python。\n当我们把 mode 赋值成 json 看看。\ndef test_env_model():    with Session(db_engine) as session:        query = select(EnvModel).where(EnvModel.is_delete == 0)        result = session.exec(query).all()        for i in result:            print(i.model_dump(mode=&quot;json&quot;))\n\n测试结果：\n$ pytest -sv app/tests/scripts_service/env_model_test.pyapp/tests/scripts_service/env_model_test.py::test_env_model &#123;&#x27;case_env_id&#x27;: &#x27;T12&#x27;, &#x27;is_delete&#x27;: 0, &#x27;id&#x27;: 1, &#x27;updated_at&#x27;: &#x27;2025-07-10T14:42:17&#x27;, &#x27;app_id&#x27;: &#x27;&#x27;, &#x27;case_env&#x27;: &#x27;***内灰&#x27;, &#x27;created_at&#x27;: &#x27;2025-07-10T14:42:17&#x27;&#125;&#123;&#x27;case_env_id&#x27;: &#x27;T1760&#x27;, &#x27;is_delete&#x27;: 0, &#x27;id&#x27;: 2, &#x27;updated_at&#x27;: &#x27;2025-07-10T20:03:44&#x27;, &#x27;app_id&#x27;: &#x27;app123456789abc&#x27;, &#x27;case_env&#x27;: &#x27;测试环境&#x27;, &#x27;created_at&#x27;: &#x27;2025-07-10T14:42:17&#x27;&#125;PASSED\n\n这下就是比较正常的数据了。\n总结当使用 model_dump() 进行模型转换时需要注意：\n\n要转换的类型需要是模型实例，而非 list\n需要指定 mode=&quot;json&quot;，否则日期格式无法正确转换\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.150-fastapi中异步函数怎么测试","url":"/2025/08/09/No-150-fastapi%E4%B8%AD%E5%BC%82%E6%AD%A5%E5%87%BD%E6%95%B0%E6%80%8E%E4%B9%88%E6%B5%8B%E8%AF%95/","content":"导读在 fastapi 中，经常会有异步函数，那么在测试的时候，怎么测试异步函数呢？\n需要使用专门的工具和方法。pytest 通过 pytest-asyncio 插件提供了对异步测试的支持。\n安装必要的包首先需要安装 pytest 和 pytest-asyncio：\npip install pytest pytest-asyncio\n\n基本异步测试1. 简单异步测试import pytestasync def async_function():    return 42@pytest.mark.asyncioasync def test_async_function():    result = await async_function()    assert result == 42\n\n2. 测试异步 HTTP 请求import pytestimport aiohttp@pytest.mark.asyncioasync def test_http_request():    async with aiohttp.ClientSession() as session:        async with session.get(&#x27;https://httpbin.org/get&#x27;) as resp:            assert resp.status == 200            data = await resp.json()            assert &#x27;url&#x27; in data\n\n高级用法1. 使用异步 fixtureimport pytest@pytest.fixtureasync def async_fixture():    # 异步设置代码    yield &quot;fixture value&quot;    # 异步清理代码@pytest.mark.asyncioasync def test_with_async_fixture(async_fixture):    assert async_fixture == &quot;fixture value&quot;\n\n2. 测试超时import pytestimport asyncioasync def slow_operation():    await asyncio.sleep(2)    return &quot;done&quot;@pytest.mark.asyncioasync def test_slow_operation():    with pytest.raises(asyncio.TimeoutError):        await asyncio.wait_for(slow_operation(), timeout=0.1)\n\n3. 测试异步异常import pytestasync def async_raise_exception():    raise ValueError(&quot;Something went wrong&quot;)@pytest.mark.asyncioasync def test_async_exception():    with pytest.raises(ValueError, match=&quot;Something went wrong&quot;):        await async_raise_exception()\n\n配置 pytest-asyncio可以在 pytest.ini 中配置 pytest-asyncio：\n[pytest]asyncio_mode = auto\n\n可选模式：\n\nstrict - 只运行标记为 @pytest.mark.asyncio 的测试\nauto - 自动检测异步测试函数\nlegacy - 旧版行为\n\n注意事项\n确保测试函数被 @pytest.mark.asyncio 装饰\n不要在同步函数中使用 await，这会导致语法错误\n对于复杂的异步测试，考虑使用 asyncio 的事件循环控制\n测试数据库操作时，确保使用支持异步的数据库驱动\n\n完整示例# my_async_module.pyasync def fetch_data(db):    await db.connect()    data = await db.query(&quot;SELECT * FROM table&quot;)    return data# test_my_async_module.pyimport pytestfrom unittest.mock import AsyncMockfrom my_async_module import fetch_data@pytest.mark.asyncioasync def test_fetch_data():    # 创建异步mock对象    mock_db = AsyncMock()    mock_db.query.return_value = [1, 2, 3]        result = await fetch_data(mock_db)        assert result == [1, 2, 3]    mock_db.connect.assert_awaited_once()    mock_db.query.assert_awaited_once_with(&quot;SELECT * FROM table&quot;)\n\n通过以上方法，你可以有效地测试 Python 中的异步代码。\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.151-fastapi中批量更新数据怎么保证数据的一致性","url":"/2025/08/10/No-151-fastapi%E4%B8%AD%E6%89%B9%E9%87%8F%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/","content":"导读在 fastapi 中，API 最常见的情况是批量更新数据，一个逻辑层的函数可能包含多次数据库交互，有新增数据、更新数据逻辑，那么在保证数据的一致性方面应该怎么做呢？\n下面我将详细说明在 FastAPI 中实现批量更新的两种主要方式，并提供完整的代码示例。\n1. 使用数据库事务实现批量更新这种方式通过数据库事务保证所有更新操作要么全部成功，要么全部失败。\n完整示例代码from fastapi import FastAPI, HTTPException, Dependsfrom pydantic import BaseModelfrom typing import Listfrom sqlalchemy import create_engine, Column, Integer, Stringfrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy.orm import sessionmaker, Session# 数据库配置SQLALCHEMY_DATABASE_URL = &quot;sqlite:///./test.db&quot;engine = create_engine(SQLALCHEMY_DATABASE_URL)SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)Base = declarative_base()# 数据库模型class User(Base):    __tablename__ = &quot;users&quot;    id = Column(Integer, primary_key=True, index=True)    name = Column(String(50))    email = Column(String(50))    status = Column(String(20))# 创建表Base.metadata.create_all(bind=engine)# Pydantic 模型class UserUpdate(BaseModel):    id: int    name: str = None    email: str = None    status: str = Noneapp = FastAPI()# 依赖项 - 获取数据库会话def get_db():    db = SessionLocal()    try:        yield db    finally:        db.close()@app.put(&quot;/users/bulk-update-transaction&quot;)async def bulk_update_users_transaction(    users: List[UserUpdate],     db: Session = Depends(get_db)):    try:        # 开始事务        db.begin()                for user_data in users:            # 查询用户            user = db.query(User).filter(User.id == user_data.id).first()            if not user:                raise HTTPException(status_code=404, detail=f&quot;User with id &#123;user_data.id&#125; not found&quot;)                        # 更新字段            if user_data.name is not None:                user.name = user_data.name            if user_data.email is not None:                user.email = user_data.email            if user_data.status is not None:                user.status = user_data.status                        # 也可以使用 merge 方法            # db.merge(user)                # 提交事务        db.commit()    except HTTPException:        # 已知异常直接抛出        db.rollback()        raise    except Exception as e:        # 其他异常回滚并返回错误        db.rollback()        raise HTTPException(status_code=500, detail=str(e))        return &#123;&quot;message&quot;: &quot;Batch update completed successfully&quot;, &quot;updated_count&quot;: len(users)&#125;\n\n关键点说明\n事务管理：\n\ndb.begin() 显式开始事务\ndb.commit() 提交事务\ndb.rollback() 在异常时回滚\n\n\n错误处理：\n\n处理了用户不存在的场景\n捕获所有异常确保事务回滚\n返回适当的HTTP状态码\n\n\n原子性保证：\n\n所有更新要么全部成功，要么全部失败\n中间出错不会导致部分更新\n\n\n\n2. 使用批量操作语句实现批量更新这种方式通过单个SQL语句执行批量更新，效率更高。\n完整示例代码2from sqlalchemy import update, bindparam@app.put(&quot;/users/bulk-update-bulk-statement&quot;)async def bulk_update_users_bulk_statement(    users: List[UserUpdate],     db: Session = Depends(get_db)):    try:        # 构建批量更新语句        stmt = (            update(User)            .where(User.id == bindparam(&#x27;user_id&#x27;))            .values(&#123;                User.name: bindparam(&#x27;user_name&#x27;),                User.email: bindparam(&#x27;user_email&#x27;),                User.status: bindparam(&#x27;user_status&#x27;)            &#125;)        )                # 准备参数列表        params = []        for user in users:            param = &#123;                &#x27;user_id&#x27;: user.id,                &#x27;user_name&#x27;: user.name,                &#x27;user_email&#x27;: user.email,                &#x27;user_status&#x27;: user.status            &#125;            params.append(param)                # 执行批量更新        result = db.execute(stmt, params)        db.commit()                # 返回更新的行数        updated_count = result.rowcount            except Exception as e:        db.rollback()        raise HTTPException(status_code=500, detail=str(e))        return &#123;        &quot;message&quot;: &quot;Batch update completed with bulk statement&quot;,        &quot;updated_count&quot;: updated_count    &#125;\n\n关键点说明2\n批量SQL构建：\n\n使用 update() 和 bindparam() 构建参数化查询\n单个SQL语句处理所有更新\n\n\n参数准备：\n\n将输入数据转换为参数列表\n每个参数对应一个字典\n\n\n执行效率：\n\n相比循环更新，减少数据库往返次数\n数据库可以优化执行计划\n\n\n返回值：\n\n通过 result.rowcount 获取实际更新的行数\n\n\n\n两种方式的比较\n\n\n特性\n事务方式\n批量语句方式\n\n\n\n实现复杂度\n简单直接\n需要构建SQL语句\n\n\n性能\n中等（多次数据库调用）\n高（单次数据库调用）\n\n\n灵活性\n高（可处理复杂逻辑）\n中（适合简单字段更新）\n\n\n错误处理\n可以逐条检查\n批量处理，难以单独处理某条失败\n\n\n适用场景\n需要复杂逻辑或验证的更新\n大批量简单字段更新\n\n\n测试示例你可以使用这样的请求体测试上述API：\n[    &#123;        &quot;id&quot;: 1,        &quot;name&quot;: &quot;New Name 1&quot;,        &quot;email&quot;: &quot;new1@example.com&quot;,        &quot;status&quot;: &quot;active&quot;    &#125;,    &#123;        &quot;id&quot;: 2,        &quot;name&quot;: &quot;New Name 2&quot;,        &quot;email&quot;: &quot;new2@example.com&quot;,        &quot;status&quot;: &quot;inactive&quot;    &#125;]\n\n实际业务中，根据你的具体需求选择合适的实现方式。\n\n对于需要复杂业务逻辑的更新，事务方式更合适；\n对于纯粹的大批量数据更新，批量语句方式性能更好。\n\n总之：在一个逻辑函数中处理事务，避免中间状态，确保原子性和一致性，尽量不要写一段逻辑提交一次，而是在逻辑函数结束时候提交或回滚一次。如果遇到高并发场景，还需要考虑锁策略。\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.152-fastapi中如何写webhook接口","url":"/2025/08/11/No-152-fastapi%E4%B8%AD%E5%A6%82%E4%BD%95%E5%86%99webhook%E6%8E%A5%E5%8F%A3/","content":"导读在构建 CICD 的过程中，经常会用到一些工具，比如：Jenkins、GitLab、Coding 等。\n这些构建工具都有一个共同点：它们能支持 webHook 的触发。\n比如 gitlib 中设置当前 push 代码的时候触发 webhook。\n当我们配置了 webhook 以后，会在触发事件发生的时候，去请求一个自定义的 url。\n这样就丰富了我们在构建 CICD 的流程中，去处理更多的业务逻辑。\nwebhook 如何自定义接口@router.post(&quot;/webhook/1.0.0&quot;, name=&quot;webhook&quot;)async def add_new(    request: Request,) -&gt; Any:    # 解析 Webhook 请求体的 JSON 数据    body = await request.body()    # 解析 JSON 数据    try:        data = json.loads(body.decode(&quot;utf-8&quot;))    except json.JSONDecodeError:        return Response(&quot;ok&quot;)    logger.info(f&quot;webhook的body=&#123;data&#125;&quot;)    # 这里添加业务逻辑    # ...    return Response(&quot;ok&quot;)\n\n说明\n请求方法定义为 post，一般要使用post方法。\n设置请求类型为 application&#x2F;json\n读取请求数据，并解析。body = await request.body()\n读取 json 数据,data = json.loads(body.decode(&quot;utf-8&quot;))，这里要注意异常的捕获，防止报错。\n在处理逻辑中，一般需要进行数据校验，避免接口报错。\n在需要使用日志信息时，要添加 logger。\n解析 body 中的参数。\n添加业务处理逻辑。\n返回 ok, 返回 ok 告诉 webhook 通知发送端，接口正常处理完成。这里要记住一定要返回 ok，否则会不停的触发事件。return Response(&quot;ok&quot;)\n\n如何测试？使用 curl 的 post 方式，带上 body 数据，示例：\ncurl --location --request POST &#x27;http://127.0.0.1:9000/webhook/1.0.0&#x27; \\--header &#x27;Content-Type: application/json&#x27; \\--data-raw &#x27;&#123;&quot;object_kind&quot;: &quot;deployment&quot;, &quot;id&quot;: 123&#125;&#x27;\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.153-fastapi中使用redis-pool连接池","url":"/2025/08/12/No-153-fastapi%E4%B8%AD%E4%BD%BF%E7%94%A8redispool%E8%BF%9E%E6%8E%A5%E6%B1%A0/","content":"导读在实际开发过程中，为了提升接口性能，我们经常会选择使用数据库连接池、redis 连接池等。\n通过连接池连接，提升效率，节省内存开销。同时通过将数据缓存到 redis 中，还可以减少网络 IO 开销。\n通常一个接口直接跟数据库交互，例如 MySQL，响应时间大概在 200ms ~ 500ms 左右。加上 redis 缓存之后，接口直接从缓存中读取，响应时间可以缩短到 10ms 左右，可以说是质的飞跃。\n下面将介绍如何在 FastAPI 中使用 redis 连接池。\n1、安装库首先确保安装了必要的 Python 包：\npip install fastapi redis uvicorn\n\n2. 添加配置在根目录下，添加 .env.dev 文件，里面是项目相关配置。\nREDIS_HOST=&quot;192.168.201.200&quot;REDIS_PORT=&quot;6379&quot;REDIS_PASSWORD=&quot;&lt;PASSWORD&gt;&quot;REDIS_DB=&quot;9&quot;\n\n在 config.py 文件中，增加如下代码，读取配置信息。\nimport osfrom typing import Annotated, Anyfrom pydantic import (    AnyUrl,    BeforeValidator,    PostgresDsn,    computed_field,)from pydantic_core import MultiHostUrlfrom pydantic_settings import BaseSettings, SettingsConfigDictclass Settings(BaseSettings):    if os.getenv(&quot;APP_ENV&quot;) == &quot;development&quot; or not os.getenv(&quot;APP_ENV&quot;):            model_config = SettingsConfigDict(                env_file=&quot;.env.dev&quot;, env_ignore_empty=True, extra=&quot;ignore&quot;            )    if os.getenv(&quot;APP_ENV&quot;) == &quot;production&quot;:        model_config = SettingsConfigDict(            env_file=&quot;/app/.env.production&quot;, env_ignore_empty=True, extra=&quot;ignore&quot;        )    if os.getenv(&quot;APP_ENV&quot;) == &quot;test&quot;:        model_config = SettingsConfigDict(            env_file=&quot;.env.test&quot;, env_ignore_empty=True, extra=&quot;ignore&quot;        )    REDIS_HOST: str    REDIS_PORT: int     REDIS_PASSWD: str     REDIS_DB: intsettings = Settings()\n\n3. 添加 redis 连接池在 db.py 中，创建 redis 连接池。\nfrom config import settingsimport redisfrom fastapi import Depends# 创建 Redis 连接池redis_pool = redis.ConnectionPool(    host=settings.REDIS_HOST,    port=settings.REDIS_PORT,    db=settings.REDIS_DB,    decode_responses=True,  # 自动解码返回的字节为字符串    max_connections=10     # 最大连接数)\n\n4. 创建deps在 deps.py 文件中，定义一个依赖项。\nimport redisfrom logger import loggerdef get_redis():    &quot;&quot;&quot;获取 Redis 连接的依赖函数&quot;&quot;&quot;    try:        redis_conn = redis.Redis(connection_pool=redis_pool)        yield redis_conn    except Exception as e:        # 可选择加入日志记录或错误上报        logger.exception(f&quot;Error occurred while managing redis pool session: &#123;e&#125;&quot;)        raise    finally:        # 这里不需要手动关闭连接，连接会返回到连接池中        passRedisPoolDep = Annotated[Redis, Depends(get_redis)]\n\n5. 使用 RedisPoolDep 依赖项在你的主应用文件（如 main.py）中使用这个连接池：\nfrom fastapi import FastAPI, Dependsfrom deps import RedisPoolDepimport redisapp = FastAPI()@app.get(&quot;/set/&#123;key&#125;/&#123;value&#125;&quot;)async def set_key_value(    key: str,     value: str,     redis_conn: RedisPoolDep):    &quot;&quot;&quot;设置键值对&quot;&quot;&quot;    redis_conn.set(key, value)    return &#123;&quot;message&quot;: f&quot;Set &#123;key&#125; = &#123;value&#125;&quot;&#125;@app.get(&quot;/get/&#123;key&#125;&quot;)async def get_key(    key: str,     redis_conn: RedisPoolDep):    &quot;&quot;&quot;获取键值&quot;&quot;&quot;    value = redis_conn.get(key)    return &#123;&quot;key&quot;: key, &quot;value&quot;: value&#125;@app.get(&quot;/info&quot;)async def redis_info(redis_conn: RedisPoolDep):    &quot;&quot;&quot;获取 Redis 服务器信息&quot;&quot;&quot;    info = redis_conn.info()    return &#123;&quot;redis_info&quot;: info&#125;\n\n总结\n创建 Redis 连接池并在应用启动时初始化\n创建依赖函数 get_redis() 来获取连接\n在路由处理函数中使用 Depends(get_redis) 注入 Redis 连接\n对于更复杂的应用，将业务逻辑封装到服务层\n考虑使用异步 Redis 客户端以提高性能, 例如 aioredis。这里有坑，慎用。。。\n使用环境变量管理配置\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.154-如何在fastapi中使用BackgroundTasks","url":"/2025/08/12/No-154-%E5%A6%82%E4%BD%95%E5%9C%A8fastapi%E4%B8%AD%E4%BD%BF%E7%94%A8BackgroundTasks/","content":"导读FastAPI 的 BackgroundTasks 功能允许你将任务添加到后台执行，这样可以在响应返回给客户端后继续处理耗时操作。\n常用的场景有发送邮件，发送短信等。\n这个功能尽量不要使用在生产环境，如果功能是边缘业务，倒是可以使用，简单方便。它的缺点就是出了问题，很难定位问题所在。需要添加详细的日志信息。\n以下是使用 BackgroundTasks 的详细指南：\n基本用法\n首先导入 BackgroundTasks：\n\nfrom fastapi import BackgroundTasks, FastAPI\n\n\n创建 FastAPI 应用并定义后台任务函数：\n\napp = FastAPI()def write_log(message: str):    with open(&quot;log.txt&quot;, mode=&quot;a&quot;) as log:        log.write(message)def send_email(email: str, message: str):    # 模拟发送电子邮件    print(f&quot;发送邮件到 &#123;email&#125;: &#123;message&#125;&quot;)\n\n\n在路径操作中使用 BackgroundTasks：\n\n@app.post(&quot;/send-notification/&#123;email&#125;&quot;)async def send_notification(email: str, background_tasks: BackgroundTasks):    background_tasks.add_task(send_email, email, message=&quot;这是一条通知&quot;)    background_tasks.add_task(write_log, f&quot;发送通知到 &#123;email&#125;&quot;)    return &#123;&quot;message&quot;: &quot;通知已发送&quot;&#125;\n\n高级用法1. 依赖注入你可以将 BackgroundTasks 作为依赖项注入：\nfrom fastapi import Dependsdef get_background_tasks(background_tasks: BackgroundTasks = BackgroundTasks()):    return background_tasks@app.post(&quot;/another-route&quot;)async def another_route(background_tasks: BackgroundTasks = Depends(get_background_tasks)):    background_tasks.add_task(some_task)    return &#123;&quot;message&quot;: &quot;任务已添加&quot;&#125;\n\n2. 与路径操作函数一起使用后台任务可以与常规路径操作函数一起使用：\n@app.post(&quot;/process-data&quot;)async def process_data(    data: dict,    background_tasks: BackgroundTasks):    # 立即处理一些数据    processed_data = &#123;k: v.upper() for k, v in data.items()&#125;        # 添加后台任务    background_tasks.add_task(store_data_in_db, processed_data)        return &#123;&quot;processed_data&quot;: processed_data&#125;\n\n3. 类方法作为后台任务你也可以使用类方法作为后台任务：\nclass NotificationService:    @classmethod    def send_email(cls, email: str, message: str):        # 发送邮件逻辑        pass@app.post(&quot;/send-email&quot;)async def send_email_route(    email: str,     background_tasks: BackgroundTasks):    background_tasks.add_task(        NotificationService.send_email,        email,        message=&quot;Hello from FastAPI&quot;    )    return &#123;&quot;status&quot;: &quot;Email will be sent&quot;&#125;\n\n注意事项\n任务顺序：添加任务的顺序就是它们执行的顺序。\n\n异常处理：后台任务中的异常不会传播到主请求，需要自行处理。\n\n测试：在测试时，可以使用 BackgroundTasks 的 tasks 属性来检查添加的任务：\n\n\ndef test_background_task():    background_tasks = BackgroundTasks()    test_app.add_task(some_task)    assert len(background_tasks.tasks) == 1\n\n\n长时间运行任务：对于非常耗时的任务，考虑使用 Celery 或其他任务队列。\n\n依赖项：后台任务函数可以接受 FastAPI 的依赖项。\n\n\n完整示例from fastapi import FastAPI, BackgroundTasksimport timeapp = FastAPI()def process_data_in_background(data: dict):    # 模拟耗时操作    time.sleep(5)    with open(&quot;processed_data.txt&quot;, &quot;a&quot;) as f:        f.write(f&quot;&#123;data&#125;\\n&quot;)@app.post(&quot;/process/&quot;)async def process_data(data: dict, background_tasks: BackgroundTasks):    background_tasks.add_task(process_data_in_background, data)    return &#123;&quot;message&quot;: &quot;数据正在后台处理&quot;, &quot;data&quot;: data&#125;\n\n通过这种方式，你可以轻松地将耗时操作放到后台执行，同时立即返回响应给客户端。\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.155-fastapi项目中Dockerfile怎么写","url":"/2025/08/14/No-155-fastapi%E9%A1%B9%E7%9B%AE%E4%B8%ADDockerfile%E6%80%8E%E4%B9%88%E5%86%99/","content":"导读fastapi 项目代码写完了，怎么打包部署？\n部署到 k8s 集群中，Dockerfile 怎么写呢？\n以下是针对 FastAPI 项目的 生产级 Dockerfile 示例，包含性能优化、安全实践和 Kubernetes 适配建议，支持异步请求和高并发场景：\n优化版 Dockerfile（支持 ASGI + 多阶段构建）# 阶段1：构建依赖FROM python:3.11-slim as builderWORKDIR /appENV PYTHONUNBUFFERED=1 \\    PIP_NO_CACHE_DIR=1 \\    PIP_DISABLE_PIP_VERSION_CHECK=1# 安装系统依赖（根据项目需求调整）RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\    gcc python3-dev &amp;&amp; \\    rm -rf /var/lib/apt/lists/*# 安装Python依赖（分层优化，利用Docker缓存）COPY requirements.txt .RUN pip install --user --no-warn-script-location -r requirements.txt# ---# 阶段2：生产镜像FROM python:3.11-slimWORKDIR /app# 从builder阶段复制已安装的Python包COPY --from=builder /root/.local /root/.local# 复制项目代码（通过.dockerignore过滤无关文件）COPY . .# 安全配置：使用非root用户RUN useradd -m appuser &amp;&amp; chown -R appuser /appUSER appuser# 环境变量ENV PATH=/home/appuser/.local/bin:$PATH \\    PYTHONUNBUFFERED=1 \\    PYTHONPATH=/app \\    UVICORN_HOST=0.0.0.0 \\    UVICORN_PORT=8000# 暴露端口EXPOSE 8000# 健康检查端点（需在FastAPI中实现/health）HEALTHCHECK --interval=30s --timeout=3s \\  CMD curl -f http://localhost:8000/health || exit 1# 启动命令（推荐使用Uvicorn + Gunicorn组合）CMD [&quot;gunicorn&quot;, &quot;-k&quot;, &quot;uvicorn.workers.UvicornWorker&quot;, &quot;--bind&quot;, &quot;0.0.0.0:8000&quot;, &quot;--workers&quot;, &quot;4&quot;, &quot;app.main:app&quot;]\n\n\n关键优化点解析\nASGI 服务器选择  \n\n使用 UvicornWorker + Gunicorn 组合：\nUvicorn 处理异步请求\nGunicorn 管理进程（建议 worker 数 &#x3D; min(2*CPU核心+1, 8)）\n\n\n\n\n安全增强  \n\n禁用 root 用户运行容器\n通过 .dockerignore 排除 __pycache__、.env 等敏感文件\n使用 --no-warn-script-location 避免权限警告\n\n\nKubernetes 适配  \n\n健康检查：在 Deployment 中配置：\nlivenessProbe:  httpGet:    path: /health    port: 8000\n\n资源限制：建议在 K8s 中设置 CPU&#x2F;Memory 限制\n\n环境变量：敏感配置通过 K8s Secrets 注入\n\n\n\n性能优化  \n\n多阶段构建减少镜像体积（最终镜像约 150MB）\n依赖分层安装（修改代码时不会重新安装依赖）\n\n\n\n\n不同场景的启动命令调整\n\n\n场景\nCMD 指令示例\n\n\n\n纯开发环境\nCMD [&quot;uvicorn&quot;, &quot;app.main:app&quot;, &quot;--reload&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;]\n\n\n高并发生产环境\nCMD [&quot;gunicorn&quot;, &quot;-k&quot;, &quot;uvicorn.workers.UvicornWorker&quot;, &quot;--bind&quot;, &quot;...&quot;]\n\n\n单节点测试\nCMD [&quot;uvicorn&quot;, &quot;app.main:app&quot;, &quot;--workers&quot;, &quot;4&quot;]\n\n\n\n配套的 requirements.txt 建议fastapi==0.109.0uvicorn==0.27.0gunicorn==21.2.0# 其他依赖...\n\n\n常见问题解决方案\n静态文件处理添加 Nginx 容器或通过 Kubernetes Ingress 配置：\nRUN pip install aiofiles  # 用于异步静态文件处理\n\nAlpine 镜像问题如需更小镜像，可替换基础镜像为 python:3.11-alpine，但需注意：\nRUN apk add --no-cache gcc musl-dev  # Alpine版gcc\n\n超时控制在 Gunicorn 中增加参数：\nCMD [&quot;gunicorn&quot;, &quot;--timeout&quot;, &quot;120&quot;, &quot;...&quot;]\n\n简版 Dockerfile (直接使用fastapi命令启动)（快速启动推荐使用）FROM python:3.12LABEL authors=&quot;&lt;your name&gt;&quot;WORKDIR /code# RUN apt-get update -y &amp;&amp; apt-get install -y python3-pip &amp;&amp; pip3 install pip --upgradeCOPY requirements.txt requirements.txtRUN pip3 install --no-cache-dir -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/COPY . .# 批量设置执行权限RUN find . -name &quot;*.sh&quot; -exec chmod +x &#123;&#125; \\;CMD [&quot;./run_main.sh&quot;]\n\nrun_main.sh:\n#! /bin/bashexport PYTHONPATH=/code:$PYTHONPATHfastapi run --port 9000\n\n本地开发环境，run_dev.sh的启动脚本：\n#! /bin/bashexport PYTHONPATH=/code:$PYTHONPATHfastapi dev --port 9000 --reload\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.156-fastapi中健康检查接口怎么写","url":"/2025/08/18/No-156-fastapi%E4%B8%AD%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%8E%A5%E5%8F%A3%E6%80%8E%E4%B9%88%E5%86%99/","content":"导读fastapi 项目代码写完了，部署的时候，运维同学要求要有 health 健康检查接口，怎么办？\n基础实现（简单版）from fastapi import FastAPI, APIRouterapp = FastAPI()# 健康检查端点@app.get(&quot;/health&quot;)async def health_check():    return &#123;&quot;status&quot;: &quot;ok&quot;, &quot;message&quot;: &quot;Service is healthy&quot;&#125;\n\n高级实现（带核心依赖检查）from fastapi import FastAPI, APIRouter, Depends, HTTPExceptionfrom sqlalchemy import textfrom redis import Redisfrom .database import SessionLocal  # 假设你有一个数据库会话app = FastAPI()# 依赖项示例def get_db():    db = SessionLocal()    try:        yield db    finally:        db.close()# Redis 连接检查def check_redis():    try:        redis = Redis(host=&quot;localhost&quot;, port=6379, db=0)        return redis.ping()    except Exception:        return False# 完整健康检查@app.get(&quot;/health&quot;)async def health_check(db: SessionLocal = Depends(get_db)):    checks = &#123;        &quot;database&quot;: False,        &quot;redis&quot;: False,        &quot;service&quot;: True    &#125;        # 数据库检查    try:        db.execute(text(&quot;SELECT 1&quot;))        checks[&quot;database&quot;] = True    except Exception as e:        pass        # Redis检查    checks[&quot;redis&quot;] = check_redis()        # 综合状态    overall_status = all(checks.values())        if not overall_status:        raise HTTPException(            status_code=503,            detail=&quot;Service Unavailable&quot;,            headers=&#123;&quot;Retry-After&quot;: &quot;10&quot;&#125;        )        return &#123;        &quot;status&quot;: &quot;ok&quot; if overall_status else &quot;degraded&quot;,        &quot;checks&quot;: checks    &#125;\n\n使用 APIRouter（推荐用于模块化）# health_router.pyfrom fastapi import APIRouter, Dependsfrom .dependencies import get_db  # 导入你的依赖项router = APIRouter(tags=[&quot;Monitoring&quot;])@router.get(&quot;/health&quot;, summary=&quot;服务健康检查&quot;, response_description=&quot;返回服务状态&quot;)async def health_check(db = Depends(get_db)):    # 实现检查逻辑...    return &#123;&quot;status&quot;: &quot;ok&quot;&#125;# main.pyfrom fastapi import FastAPIfrom .routers import health_routerapp = FastAPI()app.include_router(health_router.router)\n\n关键配置说明\n端点选择：\n\n/health：行业标准\n/healthz：Kubernetes 常用\n/ping：简单探测\n\n\n响应设计：\n&#123;  &quot;status&quot;: &quot;ok&quot;,  // 或 &quot;error&quot;/&quot;warning&quot;  &quot;version&quot;: &quot;1.0.0&quot;,  &quot;dependencies&quot;: &#123;    &quot;database&quot;: true,    &quot;cache&quot;: false  &#125;,  &quot;uptime&quot;: 12345.67&#125;\n\nHTTP状态码：\n\n200 OK：所有系统正常\n503 Service Unavailable：关键服务不可用\n\n\n性能优化：\n\n添加缓存（避免频繁检查数据库）\n设置超时（防止健康检查阻塞）\n\nfrom fastapi import BackgroundTasks@app.get(&quot;/health&quot;)async def health_check(background_tasks: BackgroundTasks):    # 将耗时检查放入后台    background_tasks.add_task(check_database)    return &#123;&quot;status&quot;: &quot;checking_in_background&quot;&#125;\n\n生产环境最佳实践\n添加安全保护：\nfrom fastapi.security import APIKeyHeaderAPI_KEY_NAME = &quot;X-HEALTH-KEY&quot;api_key_scheme = APIKeyHeader(name=API_KEY_NAME)@app.get(&quot;/health&quot;)async def secured_health(key: str = Depends(api_key_scheme)):    if key != &quot;SECRET_KEY&quot;:        raise HTTPException(status_code=403)    return &#123;&quot;status&quot;: &quot;ok&quot;&#125;\n\n集成 Prometheus 监控：\nfrom prometheus_fastapi_instrumentator import InstrumentatorInstrumentator().instrument(app).expose(app)\n\n添加版本信息：\nimport importlib.metadata@app.get(&quot;/health&quot;)async def health_check():    return &#123;        &quot;version&quot;: importlib.metadata.version(&quot;your-package&quot;),        &quot;dependencies&quot;: []    &#125;\n\n测试方法# test_health.pyfrom fastapi.testclient import TestClientfrom main import appclient = TestClient(app)def test_health_check():    response = client.get(&quot;/health&quot;)    assert response.status_code == 200    assert response.json()[&quot;status&quot;] == &quot;ok&quot;\n\n部署注意事项\n在 Kubernetes 中配置：\nlivenessProbe:  httpGet:    path: /health    port: 8000  initialDelaySeconds: 5  periodSeconds: 10readinessProbe:  httpGet:    path: /health    port: 8000  initialDelaySeconds: 30  periodSeconds: 5\n\n在负载均衡器（如 Nginx）中配置：\nlocation = /health &#123;    access_log off;    proxy_pass http://backend;&#125;\n\n这样实现的健康检查接口既满足基本需求，又能适应生产环境的复杂要求，同时保持代码的可维护性和扩展性。\n总结\n场景比较简单：直接使用基础版即可\n场景相对复杂：可考虑使用 FastAPI Router 分割模块\n需要校验 Header 需，添加 APIKey 的保护：使用 APIKeyHeader 中间件保护接口\n为了方便运维和监控：集成 Prometheus 并添加版本信息等元数据\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.157-fastapi中如何生成swagger文档","url":"/2025/08/25/No-157-fastapi%E4%B8%AD%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90swagger%E6%96%87%E6%A1%A3/","content":"导读fastapi 项目开始了，怎么快速定义 swagger 文档，供测试、前端查看呢？本文将介绍如何使用 fastapi 生成 swagger 文档。\n生成swagger文档其实，fastapi 本身就支持生成 swagger 文档，当我们使用 uvicorn 启动项目时，只需要在浏览器中输入 http://127.0.0.1:8000/docs 即可看到 swagger 文档。\n生成文档非常简单，但是标准化的文档比较难，往往需要预定好一些规则，比如参数的类型、参数的描述、参数的默认值等。如果这些规则没有统一，那么生成的文档将非常混乱，难以阅读。\n幸好，fastapi 提供了 pydantic 模块，既能用来校验接口的输入和输出，又能用来生成 swagger 文档。\npydantic使用可以参考 No.148-fastapi中使用标准化出入参自动化生成接口文档。\n生成文档直接访问 http://127.0.0.1:8000/docs 即可看到 swagger 文档。\n但是当我们需要将文档导入到第三方平台的时候，比如 postman，就需要将文档导出为 json 格式。\n可以使用命令行快速生成 json 格式的文档文件：\n# 启动项目fastapi dev --port 9000 --reload# 生成文档curl -X GET http://127.0.0.1:9000/openapi.json &gt; docs/api/swagger.json\n\n生成的文档将在 docs/api/swagger.json 文件中。再手动导入到相关平台即可。或者使用 openAPI 编写脚本自动化导入。\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.158-当我弃用pycharm改用vscode之后","url":"/2025/09/01/No-158-%E5%BD%93%E6%88%91%E5%BC%83%E7%94%A8pycharm%E6%94%B9%E7%94%A8vscode%E4%B9%8B%E5%90%8E/","content":"导读作为一名Python开发者，我使用PyCharm已经超过五年了。它无疑是一款强大的IDE，智能提示、调试功能、项目导航都无可挑剔。但随着时间的推移，一些不适开始浮现：\n内存占用惊人：打开大型项目时，PyCharm动不动就吃掉4GB+内存，我的16GB笔记本开始捉襟见肘。尤其是使用AI 插件后，内存占用更是飙升。代码补全显得很卡顿，严重影响编码体验。而且我 256GB 的 SSD 硬盘也吃不消了。\n启动速度慢：从点击图标到真正开始编码，等待时间比较久，打开 Pycharm，一般要去个卫生间再回来开始工作会比较顺畅。\n过于“重量级”：有时候我只是想快速编辑一个小脚本，却需要启动整个IDE。单个文件编辑，其实 sublime text 3 就足够了。\n尝试转变：初体验VSCode一开始我是怀疑的——一个“编辑器”真能替代“IDE”吗？\n安装必要的Python扩展后，我惊讶地发现VSCode提供了绝大多数我需要的功能：\n\n智能提示：通过Pylance扩展，代码补全几乎不输PyCharm\n调试支持：完整的断点调试、变量监视功能\n虚拟环境支持：轻松切换不同Python解释器\nGit集成：源代码管理直观易用\n\n绝了绝了。\n我也是尝试了很多次，切换到VSCode后，感觉不顺再切换回来。\n这样尝试了 7～8 次，我终于决定彻底抛弃PyCharm，拥抱VSCode。\n惊喜发现：VSCode的独特优势使用几周后，我发现了VSCode许多令人欣喜的特点：\n闪电般的启动速度：几乎瞬间启动，随时记录灵感不再是问题\n内存友好：通常内存占用只有PyCharm的1&#x2F;3到1&#x2F;2\n无缝多语言支持：前端项目常常需要同时处理Python、JavaScript、HTML，VSCode天生就是多语言环境\n扩展生态丰富：几乎任何需求都能找到对应的扩展，且安装管理极其简单\n高度可定制：通过settings.json可以精细调整每一个细节\n适应挑战：需要克服的障碍转变并非一帆风顺，确实有一些需要适应的地方：\n项目管理方式不同：VSCode以文件夹为基础而不是“项目”概念，需要时间适应\n部分高级功能需要配置：一些PyCharm开箱即用的功能，在VSCode中需要额外设置\n重构工具略逊一筹：虽然可用，但PyCharm的重构工具确实更强大\n我的VSCode Python开发配置经过不断调整，这是我的黄金配置：\n&#123;  &quot;python.linting.pylintEnabled&quot;: true,  &quot;python.linting.enabled&quot;: true,  &quot;python.formatting.provider&quot;: &quot;black&quot;,  &quot;editor.formatOnSave&quot;: true,  &quot;python.linting.pylintArgs&quot;: [&quot;--load-plugins&quot;, &quot;pylint_django&quot;],  &quot;python.linting.flake8Enabled&quot;: false,  &quot;[python]&quot;: &#123;    &quot;editor.defaultFormatter&quot;: &quot;ms-python.python&quot;,    &quot;editor.tabSize&quot;: 4  &#125;&#125;\n\n必备扩展：\n\nPython (Microsoft)\nPylance\nJupyter\nPython Docstring Generator\nBlack Formatter\nMagicPython\nPython Debug (Microsoft)\n\n结论：适合的才是最好的经过几个月的使用，我确定VSCode已经满足了我95%的Python开发需求。剩下的5%主要是超大型项目的重构和深度数据库集成，这些场景下我仍然会打开PyCharm。\n适合VSCode的场景：\n\nWeb开发（尤其是全栈开发）\n数据科学和脚本编写\n快速编辑和轻量级项目\n需要频繁切换语言的项目\n\n可能仍需PyCharm的场景：\n\n超大型项目导航和重构\n复杂的数据库集成开发\n需要IDE级深度集成的企业环境\n\n转变编辑器不是非此即彼的选择，而是找到最适合自己工作流程的工具。对我来说，VSCode提供了更好的平衡点：既强大又灵活，既功能丰富又保持轻量。\n也许有一天我会再次改变我的工具选择，但至少现在，VSCode让我享受编码的乐趣变得更加简单直接。\n安利一波：VSCode 的搜索功能是真的好用。\n\n你有类似的工具转变经历吗？欢迎在评论区分享你的故事！\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.159-fastapi中数据库隔离级别的配置的使用","url":"/2025/09/15/No-159-fastapi%E4%B8%AD%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E7%9A%84%E9%85%8D%E7%BD%AE%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"导读在做一次数据库插入数据的时候，发现重复插入问题，经过排查发现是并发导致。于是开始排查原因。\n问题原因排查经过采用分布式锁使用了分布式锁对操作数据库逻辑进行了加锁，但是发现还是会有重复插入问题。\n发现每次插入数据前都会查询一次数据，如果没有就插入，有就跳过。\n添加调试日志加了锁还是不能解决问题。于是将操作数据库前后的日志打印出来。\n发现当两个请求同时查询和插入的时候，明明已经加锁了，但是数据插入没成功，虽然每次请求都显式进行了 commit 操作。\n所以结果就是，两个请求都查询了数据库，发现没有数据，然后都插入了数据，导致重复插入。\n解决方案经过一番搜索，发现：如果你用的数据库（比如 MySQL 默认 InnoDB），事务隔离级别是 REPEATABLE READ。线程 A 插入并提交，线程 B 在插入前就开启了事务，那么它的快照还是旧的，导致查不到最新提交的数据。\n所以，解决方案就是：将数据库隔离级别改为 READ COMMITTED。\n具体 fastapi 中操作在创建数据库引擎的时候，添加 isolation_level=&quot;READ COMMITTED&quot; 参数即可。\nfrom sqlmodel import Session, create_enginefrom settings import settingsengine_o_db_ex_&lt;db_name&gt; = create_engine(    str(settings.DB_O_DB_EX_&lt;DB_NAME&gt;_URI),    pool_recycle=300,    pool_pre_ping=True,    pool_size=10,  # 连接池大小    max_overflow=20,  # 溢出连接数    isolation_level=&quot;READ COMMITTED&quot;, # 设置隔离级别)def get_db_o_ex_&lt;db_name&gt;() -&gt; Generator[Session, None, None]:    try:        with Session(engine_o_db_ex_&lt;db_name&gt;) as session:            yield session    except SQLAlchemyError as e:        # 可选择加入日志记录或错误上报        logger.exception(f&quot;Error occurred while managing session: &#123;e&#125;&quot;)        raiseDBExSessionDep = Annotated[Session, Depends(get_db_o_ex_&lt;db_name&gt;)]\n\n再使用依赖注入的方式，统一获取 Session 对象，这样在跨 Session 的情况下，就可以避免重复插入了。\n总结数据库隔离级别，这个参数在平时开发中，很少用到，但是当遇到并发问题的时候，这个参数就派上用场了。\n遇到问题，不要慌，先排查原因，可以使用 debug 模式，打印日志，一步步排查。\nMySQL 支持以下隔离级别（SQLAlchemy 里字符串要写全大写）：\n\n“READ UNCOMMITTED”\n“READ COMMITTED” ✅ 推荐，能看到别的事务已提交的数据\n“REPEATABLE READ” （MySQL 默认，可能导致你查不到刚提交的数据）\n“SERIALIZABLE”\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.160-fastapi中请求唯一标识的使用","url":"/2025/09/26/No-160-fastapi%E4%B8%AD%E8%AF%B7%E6%B1%82%E5%94%AF%E4%B8%80%E6%A0%87%E8%AF%86%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"导读在项目排查问题的过程中，链路跟踪是一个很重要的手段，通过链路跟踪，可以快速定位问题，从而快速解决问题。\n但是当没有链路跟踪的时候，我们也可以通过请求唯一标识，来追踪当前项目请求日志，从而定位问题。\n至少在本项目中能一次性全部搜索出来当前请求的日志，快速查看运行逻辑是否正确。\nfastapi 中请求唯一标识的使用添加一个中间件，将请求的唯一标识添加到请求头中。\nimport loggingfrom starlette.middleware.base import BaseHTTPMiddlewarefrom fastapi import Requestimport uuidfrom app.core.logger import loggerfrom app.core.logger import request_id_ctxclass RequestIDMiddleware(BaseHTTPMiddleware):    async def dispatch(self, request: Request, call_next):        # 获取或生成请求ID        request_id = request.headers.get(&#x27;X-Request-ID&#x27;) or str(uuid.uuid4())        request.state.request_id = request_id                # 设置上下文变量        token = request_id_ctx.set(request_id)                try:            logger.info(f&quot;Request started: &#123;request.method&#125; &#123;request.url&#125;&quot;)            response = await call_next(request)            response.headers[&#x27;X-Request-ID&#x27;] = request_id            logger.info(f&quot;Request completed: &#123;request.method&#125; &#123;request.url&#125; &#123;response.status_code&#125;&quot;)            return response        except Exception as e:            logger.error(f&quot;Request failed: &#123;request.method&#125; &#123;request.url&#125; &#123;str(e)&#125;&quot;)            raise        finally:            request_id_ctx.reset(token)\n\n主程序中添加中间件app = FastAPI(    title=settings.PROJECT_NAME,    openapi_url=f&quot;/openapi.json&quot;,    generate_unique_id_function=custom_generate_unique_id,)# 请求ID中间件app.add_middleware(RequestIDMiddleware)\n\n日志中添加请求IDimport loggingfrom concurrent_log_handler import ConcurrentRotatingFileHandlerfrom app.core.config import settingsfrom contextvars import ContextVar# 创建上下文变量存储请求IDrequest_id_ctx = ContextVar(&quot;request_id&quot;, default=None)class RequestIDFilter(logging.Filter):    def filter(self, record):        # 从当前请求上下文中获取请求ID        record.request_id = request_id_ctx.get() or &quot;no-request-id&quot;        return True\n\n设置日志格式# 设置日志的格式，可以根据需要修改formatter = logging.Formatter(    &quot;%(asctime)s &quot;    &quot;%(filename)s:%(lineno)d &quot;    &quot;%(processName)s &quot;    &quot;%(threadName)s &quot;    &quot;%(levelname)s &quot;    &quot;%(request_id)s &quot;    &quot;%(message)s&quot;)\n\n添加日志处理器logger.addFilter(RequestIDFilter())\n\n使用logger.info(&quot;This is an info message with request ID&quot;)\n\n在日志中可以看到请求ID:\n2025-09-19 18:33:00,354 middleware.py:22 MainProcess Thread-1 (run_blocking_portal) INFO 870b229f-1546-4147-873a-f3763b548db7 Request completed: POST http://testserver/coding_callback_manager/issue_status_change_first/1.0.0 5002025-09-19 18:33:54,885 middleware.py:19 MainProcess Thread-1 (run_blocking_portal) INFO f8cf2dfc-79ff-43dc-a384-f4a51c3f52c0 Request started: POST http://testserver/coding_callback_manager/issue_status_change_first/1.0.0\n\n在返回请求头中，也可以看到请求ID:\nContent-Type: application/jsonContent-Length: 66Connection: closeServer: openrestyDate: Thu, 25 Sep 2025 17:11:44 GMTX-Proxy-By: Gin Reverse ProxyX-Request-Id: 3ab700b0-b818-4d22-8e91-671ea46317e2\n\n总结\n通过请求唯一标识，可以快速定位请求的链路，从而定位问题。\n通过请求唯一标识能快速搜索出来当前请求的日志。\n可以从返回请求头中拿到请求ID，再去搜索日志。\n可以通过请求唯一 id，查询到请求开始时间和结束时间，分析请求耗时。\n可以通过逐步打印日志，来分析请求的流程，分析性能瓶颈。\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.161-fastapi中分布式锁的使用","url":"/2025/09/28/No-161-fastapi%E4%B8%AD%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"🚀 FastAPI 中分布式锁的使用：从一次“库存超卖”说起去年双 11，我接到一个临时需求：某个电商项目要在 FastAPI 微服务中接入一个限时秒杀活动。听起来很简单：下单时，先扣减库存，再生成订单。\n但活动刚开始 5 分钟，测试环境里就出现了库存被超卖的问题。\n我一脸问号：\n\n“不是加了数据库行级锁吗？怎么还会超卖？”\n\n后来排查发现：\n\nFastAPI 部署在 多实例 + 多进程 模式下。\n请求并发打到不同节点，单机锁根本没法控制全局并发。\n导致库存还没刷新，另一个节点也以为还能买。\n\n这时，我们才意识到：👉 需要一把分布式锁。\n\n🔑 为什么要分布式锁？常见场景：\n\n秒杀&#x2F;抢购：防止库存被多减\n任务调度：避免多个副本同时跑同一个任务\n接口幂等：防止重复请求造成数据重复写入\n\n在 单机环境 下，threading.Lock 就够了。但在 分布式环境（Kubernetes &#x2F; 多副本部署）下，必须要靠 Redis 这种 中心化存储 来协调。\n\n🧩 分布式锁的原理分布式锁的基本原理很简单：\n\n加锁：尝试在 Redis 设置一个 Key（只允许第一个写入成功）。\n执行业务逻辑：执行库存扣减、报表生成等。\n解锁：执行完后删除 Key，但要注意不能误删别人的锁。\n\nRedis 的 SETNX + 过期时间（EXPIRE）就能实现这一过程。\n\n⚡ 在 FastAPI 中的实战示例下面分享一个真实的业务改造案例：\nfrom contextlib import contextmanagerfrom redis import Redisfrom redis.lock import Lockimport logginglogger = logging.getLogger(__name__)redis_client = Redis(host=&quot;127.0.0.1&quot;, port=6379, decode_responses=True)@contextmanagerdef get_redis_lock(lock_key: str, timeout: int = 10):    &quot;&quot;&quot;    获取 Redis 分布式锁（上下文管理器方式）    Args:        lock_key (str): 锁的 key        timeout (int, optional): 过期时间，秒. Defaults to 10.    &quot;&quot;&quot;    lock = Lock(        redis=redis_client,        name=lock_key,        timeout=timeout,        blocking_timeout=timeout + 5,    )    acquired = False    try:        acquired = lock.acquire(blocking=True)        if not acquired:            raise Exception(f&quot;[get_redis_lock] Failed to acquire lock: &#123;lock_key&#125;&quot;)        yield lock    finally:        if acquired:            try:                lock.release()                logger.info(f&quot;[get_redis_lock] Released lock: &#123;lock_key&#125;&quot;)            except Exception as e:                logger.warning(f&quot;Lock release error: &#123;e&#125;&quot;)\n\n调用时非常优雅：\n@app.post(&quot;/seckill&quot;)def seckill():    with get_redis_lock(&quot;lock:inventory&quot;, timeout=5):        stock = int(redis_client.get(&quot;stock&quot;) or 0)        if stock &lt;= 0:            raise HTTPException(status_code=400, detail=&quot;库存不足&quot;)        redis_client.decr(&quot;stock&quot;)        return &#123;&quot;msg&quot;: &quot;秒杀成功&quot;&#125;\n\n👉 有了 with，即使代码抛异常，也能保证锁被正确释放。\n\n🧪 多副本 + 多线程脚本场景分布式锁不仅能保护接口，还能用在 后台定时任务。\n比如：多个 FastAPI 副本同时启动了一个定时脚本去生成报表，如果没加锁，结果就是——每个副本都生成一次报表，浪费资源还可能产生重复数据。\n有了 get_redis_lock：\nasync def generate_report():    with get_redis_lock(&quot;lock:report&quot;, timeout=30):        print(&quot;开始生成报表...&quot;)        await asyncio.sleep(5)  # 模拟耗时任务        print(&quot;报表生成完成 ✅&quot;)\n\n这也适用于多副本的消费者脚本场景：例如高并发情况下，多个消费者同时向数据库插入数据，虽然插入之前都会进行检查数据是否存在，但还是会出现重复数据。这个时候就需要用到分布式锁来保证数据的唯一性。\n即使部署了多个副本，也只有一个实例能拿到锁执行，避免重复任务。\n\n⚠️ 踩坑与优化\n锁过期时间太短\n\n业务没执行完，锁就过期，其他实例进来重复执行。\n✅ 解决：加“锁续期”（看门狗）。\n\n\n锁过期时间太长\n\n服务宕机后锁迟迟不释放，影响可用性。\n\n\n高并发下锁冲突严重\n\n可以结合 消息队列 来削峰填谷。\n\n\n\n\n🏁 总结那次“库存超卖”事故后，我对分布式锁有了更深的认识：\n\n在 单机时代，threading.Lock 足够。\n在 分布式环境下，Redis 分布式锁是最常用的解决方案。\n在 FastAPI 项目里，配合 @contextmanager 写法，能让锁的获取与释放更安全、优雅。\n\n一句话：\n\n分布式锁不是银弹，但在关键场景下，它是救命稻草。\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.162-fastapi中使用 celery.backend_cleanup 的工作原理","url":"/2025/10/31/No-162-fastapi%E4%B8%AD%E4%BD%BF%E7%94%A8celery.backend_cleanup%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/","content":"导读FastApi 中使用定时任务和异步任务，首选 Celery。在启动 Celery Beat 的时候，会自动初始化一个 celery.backend_cleanup 任务。那么这个任务做了哪些事情呢？工作原理是什么？怎么使用和配置呢？\n作用它的作用：\n\n遍历 result backend；\n找出超过 result_expires 时间的任务结果；\n将其删除。\n\n关键配置项：\n\n\n\n配置项\n说明\n示例\n\n\n\nresult_expires\n任务结果保存的过期时间（秒）\napp.conf.result_expires = 3600（1小时）\n\n\nresult_backend\n存储任务结果的后端\nredis://localhost:6379/0\n\n\nresult_backend_cleanup_interval（Celery 5.3+）\n清理任务运行间隔\napp.conf.result_backend_cleanup_interval = 3600\n\n\n举例配置：\napp.conf.update(    result_backend=&quot;redis://localhost:6379/0&quot;,    result_expires=3600,  # 一小时，非常重要，它决定了你的任务跑完存储的时长)\n\n命令行触发：\ncelery -A your_project call celery.backend_cleanup\n\npython调用：\nfrom celery import Celeryapp = Celery(&#x27;your_project&#x27;)app.send_task(&#x27;celery.backend_cleanup&#x27;)\n\n如果你用的 Beat scheduler 为数据库，则会创建一条定时任务数据，通常是 0 4 * * *，表示在每天的凌晨 4 点执行。\n注意事项：\n\n如果你关闭了 result_persistent&#x3D;False 或根本没用 backend（比如只 fire-and-forget），则无需关心。\n如果你用的是 数据库 作为 backend（如 Django ORM、SQLAlchemy），清理是删除数据库记录；\n如果你用的是 Redis，则清理是删除对应的 key；\n对于自定义 backend，必须实现 cleanup() 方法，否则该任务无效。\n\n工作原理\n首先判断结果数据是否过期\n再根据筛选出来的过期数据，进行删除\n\n判断过期数据的逻辑：Celery 通过比较 任务结果的存储时间 + result_expires 来判断是否过期。简化逻辑如下：\nif now() - date_done &gt; result_expires:    # 任务结果已过期，删除\n\n不同 Backend 的判断方式：\n\n\n\nBackend 类型\n过期判断方式\n说明\n\n\n\nRedis &#x2F; Memcached\n利用 key 的 TTL（过期时间）\nCelery 在写入结果时会设置 EXPIRE，Redis 自动清除\n\n\nDatabase（如 Django ORM、SQLAlchemy）\n读取 date_done 字段，对比当前时间\nCelery 定期执行 DELETE FROM celery_taskmeta WHERE date_done &lt; now() - result_expires\n\n\nRPC &#x2F; AMQP\n不持久化结果或自动过期\n一般不需清理\n\n\nFilesystem &#x2F; S3 等持久化存储\n检查保存文件的时间戳\n比对 mtime 或 metadata\n\n\nCelery.backend_cleanup\n自动清理过期数据\nCelery 定期执行 backend_cleanup，清理过期数据\n\n\n以数据库 backend 为例：在 Celery 的源码中（celery&#x2F;backends&#x2F;database&#x2F;init.py），DatabaseBackend 有一个 cleanup() 方法：\ndef cleanup(self):    session = self.ResultSession()    now = self.app.now()    expired = now - self.expires    session.query(TaskModel).filter(TaskModel.date_done &lt; expired).delete()    session.commit()\n\n过期数据常见的存储方式：\n\n\n\nBackend\n存储位置\n示例\n\n\n\nRedis\nRedis 的 key-value\nkey 类似于 celery-task-meta-&lt;uuid&gt;\n\n\nDatabase（Django ORM &#x2F; SQLAlchemy）\n数据库表中（默认表名：celery_taskmeta）\n列：id, task_id, status, result, date_done, traceback\n\n\nAMQP (RabbitMQ)\n消息队列，不持久化\n任务完成后即消费\n\n\nFilesystem\n文件系统的结果文件\n每个任务结果单独存文件\n\n\nCache backend (memcached)\n缓存中\n自动过期\n\n\nS3 &#x2F; HTTP\n远程对象存储\n带 metadata 标识时间戳\n\n\n配置和使用要使用它，需要在 celery 配置文件中添加以下配置：\n# celeryconfig.pyCELERY_RESULT_BACKEND = &#x27;redis://localhost:6379/0&#x27;CELERY_RESULT_EXPIRES = 3600  # 1 hour   过期时间，单位为秒，存储够小时就删除CELERY_RESULT_CLEANUP_INTERVAL = 60  # 1 minute，每分钟执行一次清理任务，过期任务会被自动删除\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["Celery"]},{"title":"No.163-fastapi中加载环境变量","url":"/2025/12/03/No-163-fastapi%E4%B8%AD%E5%8A%A0%E8%BD%BD%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","content":"导读在实际开发过程中，我们经常需要根据不同的环境（开发、测试、生产）使用不同的配置，比如数据库连接、Redis地址、API密钥等。\n将这些配置硬编码在代码中显然不是一个好的做法，不仅不利于维护，还会带来安全风险。\n在 FastAPI 项目中，我们可以通过环境变量来管理这些配置，实现配置与代码的分离，提高项目的可维护性和安全性。\n思路在 FastAPI 中加载环境变量主要有以下几种方式：\n\n使用 pydantic-settings（推荐）：这是 FastAPI 官方推荐的方式，基于 Pydantic 的 BaseSettings，支持类型验证、自动加载 .env 文件等特性。\n\n使用 python-dotenv：通过 python-dotenv 库手动加载 .env 文件，然后使用 os.getenv() 获取环境变量。\n\n直接使用 os.getenv()：直接从系统环境变量中读取，适合简单的场景。\n\n\n本文主要介绍使用 pydantic-settings 的方式，这是最推荐的做法。\n方案1. 安装依赖首先确保安装了必要的 Python 包：\npip install pydantic-settings\n\n2. 创建环境变量文件在项目根目录下，创建不同环境的 .env 文件：\n.env.dev（开发环境）：\nAPP_ENV=developmentDATABASE_URL=postgresql://user:password@localhost:5432/mydbREDIS_HOST=192.168.201.200REDIS_PORT=6379REDIS_PASSWORD=your_passwordREDIS_DB=9API_KEY=dev_api_keyDEBUG=True\n\n.env.production（生产环境）：\nAPP_ENV=productionDATABASE_URL=postgresql://user:password@prod-db:5432/mydbREDIS_HOST=prod-redis.example.comREDIS_PORT=6379REDIS_PASSWORD=prod_passwordREDIS_DB=0API_KEY=prod_api_keyDEBUG=False\n\n.env.test（测试环境）：\nAPP_ENV=testDATABASE_URL=postgresql://user:password@test-db:5432/mydbREDIS_HOST=test-redis.example.comREDIS_PORT=6379REDIS_PASSWORD=test_passwordREDIS_DB=1API_KEY=test_api_keyDEBUG=True\n\n3. 创建配置类在 app/core/config.py 文件中，创建配置类：\nimport osfrom pydantic_settings import BaseSettings, SettingsConfigDictclass Settings(BaseSettings):    # 根据环境变量 APP_ENV 选择不同的 .env 文件    if os.getenv(&quot;APP_ENV&quot;) == &quot;development&quot; or not os.getenv(&quot;APP_ENV&quot;):        model_config = SettingsConfigDict(            env_file=&quot;.env.dev&quot;,             env_ignore_empty=True,             extra=&quot;ignore&quot;        )    elif os.getenv(&quot;APP_ENV&quot;) == &quot;production&quot;:        model_config = SettingsConfigDict(            env_file=&quot;.env.production&quot;,             env_ignore_empty=True,             extra=&quot;ignore&quot;        )    elif os.getenv(&quot;APP_ENV&quot;) == &quot;test&quot;:        model_config = SettingsConfigDict(            env_file=&quot;.env.test&quot;,             env_ignore_empty=True,             extra=&quot;ignore&quot;        )    else:        # 默认使用 .env.dev        model_config = SettingsConfigDict(            env_file=&quot;.env.dev&quot;,             env_ignore_empty=True,             extra=&quot;ignore&quot;        )    # 项目配置    PROJECT_NAME: str = &quot;My FastAPI Project&quot;    APP_ENV: str = &quot;development&quot;    DEBUG: bool = False        # 数据库配置    DATABASE_URL: str        # Redis 配置    REDIS_HOST: str    REDIS_PORT: int    REDIS_PASSWORD: str    REDIS_DB: int        # API 配置    API_KEY: str        # 其他配置    SECRET_KEY: str = &quot;your-secret-key-here&quot;    ALGORITHM: str = &quot;HS256&quot;    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30# 创建全局配置实例settings = Settings()\n\n4. 在项目中使用配置在 app/main.py 或其他地方使用配置：\nfrom fastapi import FastAPIfrom app.core.config import settingsapp = FastAPI(    title=settings.PROJECT_NAME,    debug=settings.DEBUG,)@app.get(&quot;/&quot;)async def root():    return &#123;        &quot;message&quot;: &quot;Hello World&quot;,        &quot;environment&quot;: settings.APP_ENV,        &quot;debug&quot;: settings.DEBUG    &#125;\n\n5. 使用配置连接数据库或 Redisfrom app.core.config import settingsimport redis# 使用 Redis 配置redis_client = redis.Redis(    host=settings.REDIS_HOST,    port=settings.REDIS_PORT,    password=settings.REDIS_PASSWORD,    db=settings.REDIS_DB,    decode_responses=True)# 使用数据库配置from sqlalchemy import create_engineengine = create_engine(settings.DATABASE_URL)\n\n6. 配置说明SettingsConfigDict 参数说明：\n\nenv_file: 指定要加载的环境变量文件路径\nenv_ignore_empty: 忽略空值，如果环境变量值为空字符串，则使用默认值\nextra: 控制如何处理未定义的字段，&quot;ignore&quot; 表示忽略未定义的字段\n\n环境变量优先级：\n\n系统环境变量（最高优先级）\n.env 文件中定义的值\n类中定义的默认值（最低优先级）\n\n7. 注意事项\n不要将 .env 文件提交到版本控制系统：在 .gitignore 中添加：\n.env*!.env.example\n\n使用 .env.example 作为模板：创建一个 .env.example 文件，包含所有需要的环境变量（不包含敏感信息），供其他开发者参考。\n\n生产环境配置：在生产环境中，建议通过系统环境变量或容器环境变量来设置配置，而不是使用 .env 文件。\n\n类型验证：Pydantic 会自动进行类型验证，如果环境变量的类型不匹配，会抛出验证错误。\n\n\n总结\n使用 pydantic-settings 可以方便地管理环境变量，支持类型验证和自动加载。\n通过不同环境的 .env 文件，可以轻松切换配置。\n配置与代码分离，提高了项目的可维护性和安全性。\n环境变量优先级：系统环境变量 &gt; .env 文件 &gt; 默认值。\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"No.164-fastapi中请求接口用httpx还是requests","url":"/2025/12/09/No-164-fastapi%E4%B8%AD%E8%AF%B7%E6%B1%82%E6%8E%A5%E5%8F%A3%E7%94%A8httpx%E8%BF%98%E6%98%AFrequests/","content":"导读在 FastAPI 项目中，我们经常需要调用外部 API 接口。Python 生态中有两个主流的 HTTP 客户端库：requests 和 httpx。\nrequests 是 Python 中最流行的同步 HTTP 库，而 httpx 是一个现代化的 HTTP 客户端，同时支持同步和异步操作。\n那么在 FastAPI 这种异步框架中，我们应该选择哪个呢？本文将从技术特性、性能、兼容性等多个维度进行深入分析。\nhttpx vs requests：核心区别1. 异步支持httpx：\n\n原生支持异步操作，基于 asyncio\n可以无缝集成到 FastAPI 的异步路由中\n支持 async/await 语法\n\nrequests：\n\n仅支持同步操作\n在异步环境中使用会阻塞事件循环\n需要使用线程池或 asyncio.to_thread() 包装\n\n2. HTTP&#x2F;2 支持httpx：\n\n原生支持 HTTP&#x2F;2 协议\n可以提升性能，特别是在需要多次请求的场景下\n\nrequests：\n\n仅支持 HTTP&#x2F;1.1\n不支持 HTTP&#x2F;2\n\n3. 性能对比\n\n\n特性\nhttpx\nrequests\n\n\n\n异步支持\n✅ 原生支持\n❌ 需要包装\n\n\nHTTP&#x2F;2\n✅ 支持\n❌ 不支持\n\n\n连接池\n✅ 自动管理\n✅ 支持\n\n\n超时控制\n✅ 更灵活\n✅ 支持\n\n\n流式响应\n✅ 支持\n✅ 支持\n\n\n并发性能\n✅ 优秀\n⚠️ 受限于 GIL\n\n\n4. API 设计httpx：\n\nAPI 设计与 requests 高度相似，学习成本低\n支持同步和异步两种模式\n更现代的 Python 特性支持\n\nrequests：\n\n成熟稳定，API 简洁直观\n生态丰富，文档完善\n仅支持同步模式\n\n5. 代码示例对比在 FastAPI 中使用 httpx（推荐）异步模式（推荐）：\nfrom fastapi import FastAPIimport httpxapp = FastAPI()@app.get(&quot;/fetch-data&quot;)async def fetch_data():    async with httpx.AsyncClient() as client:        response = await client.get(&quot;https://api.example.com/data&quot;)        return response.json()\n\n同步模式（httpx 也支持同步操作，API 与 requests 几乎一致）：\nimport httpx# 方式1：使用上下文管理器（推荐）with httpx.Client() as client:    response = client.get(&quot;https://api.example.com/data&quot;)    data = response.json()# 方式2：直接调用（不推荐，需要手动关闭）client = httpx.Client()try:    response = client.get(&quot;https://api.example.com/data&quot;)    data = response.json()finally:    client.close()# 方式3：一次性请求（最简单，适合单次请求）response = httpx.get(&quot;https://api.example.com/data&quot;)data = response.json()# 同步模式也支持高级特性with httpx.Client(    timeout=httpx.Timeout(10.0, connect=5.0),    http2=True,  # 同步模式也支持 HTTP/2    headers=&#123;&quot;Authorization&quot;: &quot;Bearer token&quot;&#125;) as client:    response = client.post(        &quot;https://api.example.com/data&quot;,        json=&#123;&quot;key&quot;: &quot;value&quot;&#125;    )    response.raise_for_status()    return response.json()\n\n同步 vs 异步对比：\n# 同步模式（httpx.Client）with httpx.Client() as client:    response = client.get(&quot;https://api.example.com/data&quot;)# 异步模式（httpx.AsyncClient）async with httpx.AsyncClient() as client:    response = await client.get(&quot;https://api.example.com/data&quot;)\n\n在 FastAPI 中使用 requests（不推荐）from fastapi import FastAPIimport requestsimport asyncioapp = FastAPI()@app.get(&quot;/fetch-data&quot;)async def fetch_data():    # 方式1：使用 asyncio.to_thread（Python 3.9+）    response = await asyncio.to_thread(        requests.get, &quot;https://api.example.com/data&quot;    )    return response.json()        # 方式2：使用线程池（不推荐，性能较差）    # loop = asyncio.get_event_loop()    # response = await loop.run_in_executor(    #     None, requests.get, &quot;https://api.example.com/data&quot;    # )    # return response.json()\n\n6. 高级特性对比httpx 的高级特性import httpx# 1. 支持 HTTP/2async with httpx.AsyncClient(http2=True) as client:    response = await client.get(&quot;https://example.com&quot;)# 2. 支持流式请求和响应async with httpx.AsyncClient() as client:    async with client.stream(&quot;GET&quot;, &quot;https://example.com&quot;) as response:        async for chunk in response.aiter_bytes():            process_chunk(chunk)# 3. 支持 WebSocket（额外安装 httpx[ws]）async with httpx.AsyncClient() as client:    async with client.websocket_connect(&quot;wss://example.com/ws&quot;) as ws:        await ws.send_text(&quot;Hello&quot;)        message = await ws.receive_text()# 4. 更灵活的超时配置timeout = httpx.Timeout(10.0, connect=5.0)async with httpx.AsyncClient(timeout=timeout) as client:    response = await client.get(&quot;https://example.com&quot;)\n\nrequests 的特性import requests# 1. 流式响应response = requests.get(&quot;https://example.com&quot;, stream=True)for chunk in response.iter_content(chunk_size=8192):    process_chunk(chunk)# 2. 会话管理session = requests.Session()session.headers.update(&#123;&quot;Authorization&quot;: &quot;Bearer token&quot;&#125;)response = session.get(&quot;https://api.example.com/data&quot;)\n\n7. 依赖和兼容性httpx：\n\n依赖较少，但需要 Python 3.8+\n与 FastAPI、Starlette 等异步框架完美集成\n可以替代 requests 的大部分功能\n\nrequests：\n\n依赖 urllib3，生态成熟\nPython 2.7+ 和 Python 3.x 都支持\n在同步代码中表现优秀\n\n总结：什么时候用哪个？推荐使用 httpx 的场景\nFastAPI 异步路由中调用外部 API（强烈推荐）\n\n原生异步支持，不会阻塞事件循环\n性能更好，可以充分利用异步并发\n\n\n需要 HTTP&#x2F;2 支持\n\n某些现代 API 服务要求或推荐使用 HTTP&#x2F;2\n\n\n高并发场景\n\n需要同时发起大量 HTTP 请求\n异步特性可以显著提升性能\n\n\n需要 WebSocket 支持\n\nhttpx 可以处理 WebSocket 连接\n\n\n\n可以使用 requests 的场景\n同步代码环境\n\n不在异步框架中，使用 requests 更简单直接\n注意：httpx 也支持同步模式（httpx.Client），API 与 requests 几乎一致，可以作为 requests 的现代化替代\n\n\n已有大量 requests 代码\n\n迁移成本较高，可以继续使用\n但建议逐步迁移到 httpx（同步模式迁移成本很低）\n\n\n简单的脚本或工具\n\n不需要异步特性，requests 足够使用\n也可以考虑使用 httpx 的同步模式，获得更好的性能和 HTTP&#x2F;2 支持\n\n\n\n在 FastAPI 中的最佳实践from fastapi import FastAPI, HTTPExceptionimport httpxfrom typing import Optionalapp = FastAPI()# 创建全局的 httpx 客户端（推荐）# 这样可以复用连接，提升性能httpx_client = httpx.AsyncClient(    timeout=httpx.Timeout(10.0, connect=5.0),    limits=httpx.Limits(max_keepalive_connections=20, max_connections=100))@app.on_event(&quot;shutdown&quot;)async def shutdown():    await httpx_client.aclose()@app.get(&quot;/api/proxy&quot;)async def proxy_external_api():    try:        response = await httpx_client.get(&quot;https://api.example.com/data&quot;)        response.raise_for_status()        return response.json()    except httpx.HTTPError as e:        raise HTTPException(status_code=500, detail=f&quot;External API error: &#123;str(e)&#125;&quot;)\n\n注意事项：\n\n使用全局客户端可以复用连接，提升性能\n记得在应用关闭时调用 aclose() 关闭客户端\n合理设置超时和连接限制，避免资源耗尽\n\n结论在 FastAPI 项目中，强烈推荐使用 httpx，原因如下：\n\n原生异步支持：与 FastAPI 的异步特性完美匹配，不会阻塞事件循环\n更好的性能：在高并发场景下，异步特性可以显著提升性能\n现代化特性：支持 HTTP&#x2F;2、WebSocket 等现代协议\nAPI 兼容：与 requests API 高度相似，迁移成本低\n官方推荐：FastAPI 官方文档中也推荐使用 httpx 进行异步 HTTP 请求\n\n虽然 requests 仍然是一个优秀的库，但在异步框架中使用它会带来性能损失和代码复杂度。除非有特殊原因（如需要兼容旧代码），否则在 FastAPI 中应该优先选择 httpx。\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi","httpx","requests"]},{"title":"No.165-fastapi中校验crontab表达式格式","url":"/2025/12/16/No-165-fastapi%E4%B8%AD%E6%A0%A1%E9%AA%8Ccrontab%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A0%BC%E5%BC%8F/","content":"导读在 FastAPI 项目中，我们经常需要处理定时任务相关的功能。当用户需要配置定时任务时，通常会使用 crontab 表达式来指定任务的执行时间。\ncrontab 表达式由 5 个字段组成，分别表示：分钟、小时、日期、月份、星期。格式为：分 时 日 月 周。\n为了确保用户输入的 crontab 表达式格式正确，我们需要在接口层进行校验。本文将介绍如何在 FastAPI 中使用 Pydantic 自定义验证器来校验 crontab 表达式格式。\n思路在 FastAPI 中校验 crontab 表达式格式，主要有以下几种方式：\n\n使用 Pydantic 自定义验证器（推荐）：通过 @field_validator 或 @model_validator 装饰器创建自定义验证逻辑，可以无缝集成到 FastAPI 的请求验证中。\n\n使用正则表达式：通过正则表达式匹配 crontab 表达式的格式，但这种方式只能验证格式，无法验证值的有效性。\n\n使用第三方库：如 croniter 库，可以解析和验证 crontab 表达式。\n\n\n本文主要介绍使用 Pydantic 自定义验证器结合 croniter 库的方式，这是最推荐的做法。\n方案1. 安装依赖首先确保安装了必要的 Python 包：\npip install fastapi pydantic croniter pytest httpx\n\n2. 创建 crontab 验证器在 app/utils/validators.py 文件中，创建 crontab 表达式验证器：\nfrom pydantic import field_validatorfrom croniter import croniterfrom datetime import datetimedef validate_crontab(crontab_str: str) -&gt; str:    &quot;&quot;&quot;    验证 crontab 表达式格式        Args:        crontab_str: crontab 表达式字符串            Returns:        str: 验证通过的 crontab 表达式            Raises:        ValueError: 如果 crontab 表达式格式不正确    &quot;&quot;&quot;    if not crontab_str:        raise ValueError(&quot;crontab 表达式不能为空&quot;)        # 使用 croniter 验证 crontab 表达式    try:        # 尝试解析 crontab 表达式        cron = croniter(crontab_str, datetime.now())        # 尝试获取下一个执行时间，如果成功说明表达式有效        cron.get_next(datetime)    except Exception as e:        raise ValueError(f&quot;无效的 crontab 表达式: &#123;str(e)&#125;&quot;)        return crontab_str\n\n3. 在 Pydantic 模型中使用验证器在 app/schemas/task.py 文件中，创建任务模型：\nfrom pydantic import BaseModel, Field, field_validatorfrom typing import Optionalfrom app.utils.validators import validate_crontabclass TaskCreateRequest(BaseModel):    &quot;&quot;&quot;创建任务请求模型&quot;&quot;&quot;    name: str = Field(..., description=&quot;任务名称&quot;, min_length=1, max_length=100)    crontab: str = Field(..., description=&quot;crontab 表达式，格式：分 时 日 月 周&quot;)    description: Optional[str] = Field(default=None, description=&quot;任务描述&quot;, max_length=500)        @field_validator(&#x27;crontab&#x27;)    @classmethod    def validate_crontab_format(cls, v: str) -&gt; str:        &quot;&quot;&quot;验证 crontab 表达式格式&quot;&quot;&quot;        return validate_crontab(v)        class Config:        json_schema_extra = &#123;            &quot;example&quot;: &#123;                &quot;name&quot;: &quot;定时数据同步任务&quot;,                &quot;crontab&quot;: &quot;0 2 * * *&quot;,                &quot;description&quot;: &quot;每天凌晨2点执行数据同步&quot;            &#125;        &#125;\n\n4. 在 FastAPI 路由中使用在 app/routers/task.py 文件中，创建任务接口：\nfrom fastapi import APIRouter, HTTPExceptionfrom app.schemas.task import TaskCreateRequestfrom typing import Listrouter = APIRouter(prefix=&quot;/api/tasks&quot;, tags=[&quot;任务管理&quot;])@router.post(&quot;/&quot;, summary=&quot;创建定时任务&quot;)async def create_task(task: TaskCreateRequest):    &quot;&quot;&quot;    创建定时任务        - **name**: 任务名称    - **crontab**: crontab 表达式，格式：分 时 日 月 周        - 示例：`0 2 * * *` 表示每天凌晨2点执行        - 示例：`*/5 * * * *` 表示每5分钟执行一次        - 示例：`0 9-17 * * 1-5` 表示工作日上午9点到下午5点每小时执行    - **description**: 任务描述（可选）    &quot;&quot;&quot;    # 这里可以添加实际的业务逻辑    # 例如：保存任务到数据库、启动定时任务等        return &#123;        &quot;message&quot;: &quot;任务创建成功&quot;,        &quot;task&quot;: &#123;            &quot;name&quot;: task.name,            &quot;crontab&quot;: task.crontab,            &quot;description&quot;: task.description        &#125;    &#125;@router.get(&quot;/&quot;, summary=&quot;获取任务列表&quot;)async def get_tasks():    &quot;&quot;&quot;获取所有任务列表&quot;&quot;&quot;    # 这里可以添加实际的业务逻辑    return &#123;        &quot;tasks&quot;: []    &#125;\n\n5. crontab 表达式格式说明crontab 表达式由 5 个字段组成，用空格分隔：\n\n\n\n字段\n取值范围\n说明\n\n\n\n分钟\n0-59\n每小时的第几分钟执行\n\n\n小时\n0-23\n每天的第几小时执行\n\n\n日期\n1-31\n每月的第几天执行\n\n\n月份\n1-12\n每年的第几月执行\n\n\n星期\n0-7\n每周的第几天执行（0和7都表示周日）\n\n\n特殊字符说明：\n\n*：表示所有可能的值\n,：表示列表值，如 1,3,5 表示 1、3、5\n-：表示范围值，如 1-5 表示 1 到 5\n/：表示步长值，如 */5 表示每 5 个单位\n\n常用示例：\n\n0 2 * * *：每天凌晨2点执行\n*/5 * * * *：每5分钟执行一次\n0 9-17 * * 1-5：工作日上午9点到下午5点每小时执行\n0 0 1 * *：每月1号凌晨执行\n0 0 * * 0：每周日凌晨执行\n\n测试使用 pytest 编写测试用例在 tests/test_crontab_validation.py 文件中，编写测试用例：\nimport pytestfrom fastapi.testclient import TestClientfrom fastapi import FastAPIfrom app.schemas.task import TaskCreateRequestfrom app.routers.task import routerfrom pydantic import ValidationError# 创建测试应用app = FastAPI()app.include_router(router)client = TestClient(app)class TestCrontabValidation:    &quot;&quot;&quot;测试 crontab 表达式验证&quot;&quot;&quot;        def test_valid_crontab_expressions(self):        &quot;&quot;&quot;测试有效的 crontab 表达式&quot;&quot;&quot;        valid_expressions = [            &quot;0 2 * * *&quot;,          # 每天凌晨2点            &quot;*/5 * * * *&quot;,        # 每5分钟            &quot;0 9-17 * * 1-5&quot;,     # 工作日上午9点到下午5点            &quot;0 0 1 * *&quot;,          # 每月1号            &quot;0 0 * * 0&quot;,          # 每周日            &quot;30 14 * * *&quot;,        # 每天下午2点30分            &quot;0 */2 * * *&quot;,        # 每2小时            &quot;0 0 1,15 * *&quot;,       # 每月1号和15号        ]                for crontab in valid_expressions:            task = TaskCreateRequest(                name=&quot;测试任务&quot;,                crontab=crontab            )            assert task.crontab == crontab        def test_invalid_crontab_expressions(self):        &quot;&quot;&quot;测试无效的 crontab 表达式&quot;&quot;&quot;        invalid_expressions = [            &quot;&quot;,                    # 空字符串            &quot;0 2 * *&quot;,            # 字段数量不足            &quot;0 2 * * * *&quot;,        # 字段数量过多            &quot;60 * * * *&quot;,         # 分钟超出范围            &quot;* 25 * * *&quot;,         # 小时超出范围            &quot;* * 32 * *&quot;,         # 日期超出范围            &quot;* * * 13 *&quot;,         # 月份超出范围            &quot;* * * * 8&quot;,          # 星期超出范围            &quot;abc * * * *&quot;,        # 非数字字符            &quot;0-60 * * * *&quot;,       # 范围超出限制        ]                for crontab in invalid_expressions:            with pytest.raises(ValidationError):                TaskCreateRequest(                    name=&quot;测试任务&quot;,                    crontab=crontab                )        def test_create_task_with_valid_crontab(self):        &quot;&quot;&quot;测试使用有效的 crontab 表达式创建任务&quot;&quot;&quot;        response = client.post(            &quot;/api/tasks/&quot;,            json=&#123;                &quot;name&quot;: &quot;定时数据同步任务&quot;,                &quot;crontab&quot;: &quot;0 2 * * *&quot;,                &quot;description&quot;: &quot;每天凌晨2点执行数据同步&quot;            &#125;        )        assert response.status_code == 200        data = response.json()        assert data[&quot;message&quot;] == &quot;任务创建成功&quot;        assert data[&quot;task&quot;][&quot;crontab&quot;] == &quot;0 2 * * *&quot;        def test_create_task_with_invalid_crontab(self):        &quot;&quot;&quot;测试使用无效的 crontab 表达式创建任务&quot;&quot;&quot;        response = client.post(            &quot;/api/tasks/&quot;,            json=&#123;                &quot;name&quot;: &quot;定时数据同步任务&quot;,                &quot;crontab&quot;: &quot;60 * * * *&quot;,  # 无效的分钟值                &quot;description&quot;: &quot;测试无效表达式&quot;            &#125;        )        assert response.status_code == 422  # 422 表示验证错误        data = response.json()        assert &quot;detail&quot; in data        def test_create_task_with_empty_crontab(self):        &quot;&quot;&quot;测试使用空的 crontab 表达式创建任务&quot;&quot;&quot;        response = client.post(            &quot;/api/tasks/&quot;,            json=&#123;                &quot;name&quot;: &quot;定时数据同步任务&quot;,                &quot;crontab&quot;: &quot;&quot;,  # 空字符串                &quot;description&quot;: &quot;测试空表达式&quot;            &#125;        )        assert response.status_code == 422        data = response.json()        assert &quot;detail&quot; in data        def test_create_task_with_missing_crontab(self):        &quot;&quot;&quot;测试缺少 crontab 字段的请求&quot;&quot;&quot;        response = client.post(            &quot;/api/tasks/&quot;,            json=&#123;                &quot;name&quot;: &quot;定时数据同步任务&quot;,                &quot;description&quot;: &quot;缺少 crontab 字段&quot;            &#125;        )        assert response.status_code == 422        data = response.json()        assert &quot;detail&quot; in dataclass TestCrontabEdgeCases:    &quot;&quot;&quot;测试 crontab 表达式的边界情况&quot;&quot;&quot;        def test_crontab_with_special_characters(self):        &quot;&quot;&quot;测试包含特殊字符的 crontab 表达式&quot;&quot;&quot;        special_cases = [            (&quot;0 0 * * 0,7&quot;, True),    # 星期使用 0 和 7 都表示周日            (&quot;0 0 1-3 * *&quot;, True),     # 日期范围            (&quot;*/1 * * * *&quot;, True),    # 步长为1            (&quot;0 0 29-31 * *&quot;, True),  # 月末日期        ]                for crontab, should_pass in special_cases:            if should_pass:                task = TaskCreateRequest(                    name=&quot;测试任务&quot;,                    crontab=crontab                )                assert task.crontab == crontab            else:                with pytest.raises(ValidationError):                    TaskCreateRequest(                        name=&quot;测试任务&quot;,                        crontab=crontab                    )\n\n运行测试在项目根目录下运行测试：\n# 运行所有测试pytest tests/test_crontab_validation.py -v# 运行特定测试类pytest tests/test_crontab_validation.py::TestCrontabValidation -v# 运行特定测试方法pytest tests/test_crontab_validation.py::TestCrontabValidation::test_valid_crontab_expressions -v# 显示测试覆盖率pytest tests/test_crontab_validation.py --cov=app --cov-report=html\n\n完整示例代码项目结构project/├── app/│   ├── __init__.py│   ├── main.py│   ├── routers/│   │   ├── __init__.py│   │   └── task.py│   ├── schemas/│   │   ├── __init__.py│   │   └── task.py│   └── utils/│       ├── __init__.py│       └── validators.py├── tests/│   ├── __init__.py│   └── test_crontab_validation.py└── requirements.txt\n\n依赖文件requirements.txt:\nfastapi&gt;=0.104.0pydantic&gt;=2.0.0croniter&gt;=2.0.0pytest&gt;=7.4.0httpx&gt;=0.25.0\n\n总结通过使用 Pydantic 自定义验证器和 croniter 库，我们可以在 FastAPI 中轻松实现对 crontab 表达式格式的校验。这种方式具有以下优点：\n\n类型安全：利用 Pydantic 的类型系统，确保数据类型正确\n自动文档生成：FastAPI 会自动生成 API 文档，包含验证规则\n错误提示清晰：验证失败时，会返回详细的错误信息\n易于测试：可以编写单元测试和集成测试，确保验证逻辑正确\n可扩展性强：可以轻松添加更多的验证规则\n\n在实际项目中，建议将验证逻辑封装成独立的函数或类，便于复用和维护。\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi","crontab","pydantic","pytest"]},{"title":"No.166-FastAPI 不用 SQLModel，如何用 DBUtils 直连 MySQL 数据库","url":"/2025/12/18/No-166-fastapi%E4%B8%8D%E4%BD%BF%E7%94%A8sqlmodel%E8%BF%98%E5%8F%AF%E4%BB%A5%E6%80%8E%E4%B9%88%E7%9B%B4%E8%BF%9E%E6%95%B0%E6%8D%AE%E5%BA%93/","content":"导读很多同学在用 FastAPI 做项目时，第一反应就是：上 ORM，用 SQLModel、SQLAlchemy 这一套。\n但在不少业务场景下，我们其实并不需要完整的 ORM 能力，而是更希望：\n\n沿用 DBA 已经写好的 SQL，后端只负责调用；\n自己手写 SQL，精细控制索引、锁、执行计划；\n项目体量不大，上 ORM 反而增加心智负担和调试成本。\n\n这时候一个很自然的问题就来了：\n\n在 FastAPI 里，如果我不用 SQLModel，只想直连 MySQL 数据库并执行 SQL，还能不能优雅一点？\n\n答案是：完全可以，而且还可以做得很专业。\n这篇文章我们就用一个实战方案，带你搞懂：\n\n如何在 FastAPI 中用 DBUtils 管理 MySQL 连接池；\n不用 SQLModel，只靠 pymysql + 手写 SQL 就能跑通生产项目；\n如何写出既性能稳定又易于维护的数据库访问代码。\n\n\n一、为什么一定要上连接池？先统一一个共识：不用 SQLModel ≠ 裸连数据库。\n如果只是简单地在接口里：\nimport pymysqlconn = pymysql.connect(...)# 执行 SQLconn.close()\n\n在本地测试、Demo 场景当然没问题。但一旦到了线上高并发环境，很容易踩坑：\n\n每个请求都新建连接：频繁 TCP 握手、认证，开销大、延迟高；\n容易忘记关闭连接：代码分支一复杂，没处理好的地方就会连接泄漏；\n连接数量不可控：并发上来后，MySQL 连接数很容易被打满。\n\n为了同时兼顾“直连 SQL 的灵活性”和“生产级的稳定性”，最合适的做法就是：\n\n连接池 + 手写 SQL\n\n这里我们选择：\n\n驱动：pymysql（同步 MySQL 驱动，生态成熟）；\n连接池：DBUtils（专门做数据库连接池的库，简单好用）。\n\nFastAPI 支持同步视图函数（def）和异步视图函数（async def），我们完全可以：\n\n用 同步代码 + 连接池 处理数据库；\n用 FastAPI 的依赖注入管理连接的“借用&#x2F;归还”。\n\n\n二、方案整体设计我们希望做到几件事：\n\n应用启动时，创建一个 MySQL 连接池；\n每个请求到来时，从池里借出一个连接；\n业务代码只需要：\n获取连接 → 执行 SQL → 提交&#x2F;回滚 → 归还连接；\n\n\n应用关闭时，优雅关闭连接池，释放资源。\n\n用更形象的话来讲：\n\n把「连接池」当做停车场：\n\n启动时建好停车场（创建一定数量的连接）；\n每辆车（每个请求）来时，从停车场里“借一个车位”（拿一个连接）；\n用完了就把车位还回去（连接归还给池子）；\n停车场本身负责车位的总数控制和资源清理。\n\n\n下面我们一步步实现这个方案。\n\n三、安装依赖我们需要的核心依赖有：\n\nfastapi：Web 框架；\nuvicorn：ASGI 服务器；\npymysql：MySQL 驱动；\nDBUtils：连接池管理库。\n\npip install fastapi uvicorn pymysql DBUtils\n\n踩坑日记：ModuleNotFoundError: No module named ‘DBUtils’这里顺便记录一下一个非常常见、但又挺“迷惑”的报错：\nModuleNotFoundError: No module named &#x27;DBUtils&#x27;\n\n明明你已经写了：\npip install DBUtils\n\n代码里也老老实实：\nfrom DBUtils.PooledDB import PooledDB\n\n却还是报模块找不到，常见原因有几类：\n\n安装到的环境不对：\n\n例如你在系统 Python 或某个虚拟环境里装的包，\n但运行 FastAPI 服务用的是另外一个 Python 解释器；\n用 which python &#x2F; which uvicorn 或 pip show DBUtils 检查一下是否同一个环境。\n\n\npip 和 python 版本不匹配：\n\n例如 python3 在用，结果你执行的是 pip（对应 Python 2 或别的环境）；\n可以强制指定：python3 -m pip install DBUtils 或 python -m pip install DBUtils，确保装到当前 Python 里。\n\n\n容器 &#x2F; 线上环境漏装依赖：\n\n本地可以 import，是因为你本地装过；\nDocker 镜像或服务器没跑 pip install DBUtils，需要在 requirements.txt 或构建脚本里补上。\n\n\n不同版本&#x2F;发行版的包名和导入路径不一致：\n\n有些环境你会看到写法是：from dbutils.pooled_db import PooledDB（全小写 dbutils）；\n有些环境则是：from DBUtils.PooledDB import PooledDB（首字母大写的 DBUtils）；\n核心原则是：以 pip show 和官方文档为准，确认你当前安装的包名和推荐的导入路径。\n\n\n\n我的经验是：\n\n先在启动 FastAPI 的同一个环境里执行：\npython -c &quot;import DBUtils; print(DBUtils.__file__)&quot;\n\n或者：\npython -c &quot;from dbutils.pooled_db import PooledDB; print(PooledDB)&quot;\n\n能跑通就说明模块和导入路径是对的；\n\n如果这里都报 ModuleNotFoundError，那就 99% 是装错环境或没装，重新用 python -m pip install DBUtils 或对应的小写包名装一次通常就好了。\n\n\n\n四、封装 DBUtils MySQL 连接池先写一个单独的模块，比如 db.py，专门负责：\n\n创建&#x2F;关闭连接池；\n从连接池获取连接；\n和 FastAPI 生命周期集成。\n\n# db.pyfrom contextlib import contextmanagerfrom typing import Generatorimport pymysqlfrom DBUtils.PooledDB import PooledDBfrom fastapi import FastAPIclass MySQLPool:    &quot;&quot;&quot;基于 DBUtils 的 MySQL 连接池封装。&quot;&quot;&quot;    def __init__(        self,        host: str,        port: int,        user: str,        password: str,        database: str,        min_cached: int = 1,        max_cached: int = 5,        max_connections: int = 10,        charset: str = &quot;utf8mb4&quot;,    ) -&gt; None:        self._pool: PooledDB | None = None        self._pool_config = &#123;            &quot;creator&quot;: pymysql,  # 使用 pymysql 作为驱动            &quot;host&quot;: host,            &quot;port&quot;: port,            &quot;user&quot;: user,            &quot;password&quot;: password,            &quot;database&quot;: database,            &quot;charset&quot;: charset,            &quot;mincached&quot;: min_cached,  # 启动时创建的空闲连接数量            &quot;maxcached&quot;: max_cached,  # 连接池中最多缓存的连接数量            &quot;maxconnections&quot;: max_connections,  # 最大连接数            &quot;blocking&quot;: True,  # 连接数耗尽时是否阻塞等待            &quot;ping&quot;: 1,  # 检查连接是否可用        &#125;    def init_pool(self) -&gt; None:        &quot;&quot;&quot;在应用启动时创建连接池。&quot;&quot;&quot;        if self._pool is None:            self._pool = PooledDB(**self._pool_config)    def close_pool(self) -&gt; None:        &quot;&quot;&quot;在应用关闭时清理连接池（如果需要）。&quot;&quot;&quot;        # 对于 DBUtils，连接池自己会管理底层连接的释放，这里一般不用显式关闭。        self._pool = None    @contextmanager    def connection(self) -&gt; Generator[pymysql.connections.Connection, None, None]:        &quot;&quot;&quot;从连接池获取一个连接，使用 with 语法自动归还。&quot;&quot;&quot;        if self._pool is None:            raise RuntimeError(&quot;Connection pool is not initialized&quot;)        conn = self._pool.connection()        try:            yield conn        finally:            # DBUtils 的 connection() 返回的是一个封装对象，            # 调用 close() 实际上是把连接归还给连接池。            conn.close()# 可以根据实际环境调整这些配置mysql_pool = MySQLPool(    host=&quot;127.0.0.1&quot;,    port=3306,    user=&quot;root&quot;,    password=&quot;password&quot;,    database=&quot;mydb&quot;,)def init_app(app: FastAPI) -&gt; None:    &quot;&quot;&quot;把连接池初始化逻辑挂到 FastAPI 生命周期上。&quot;&quot;&quot;    @app.on_event(&quot;startup&quot;)    def _startup() -&gt; None:  # noqa: D401        # 应用启动时创建连接池        mysql_pool.init_pool()    @app.on_event(&quot;shutdown&quot;)    def _shutdown() -&gt; None:  # noqa: D401        # 应用关闭时清理连接池引用        mysql_pool.close_pool()\n\n这里有几个关键点：\n\nMySQLPool 封装了 DBUtils 的 PooledDB，避免在业务代码里直接操作底层细节；\n通过 @contextmanager 提供 connection() 方法：\n可以 with mysql_pool.connection() as conn: 的写法；\nwith 代码块结束时，会自动把连接归还给连接池；\n\n\n通过 init_app(app) 把连接池和 FastAPI 的 startup &#x2F; shutdown 生命周期绑定在一起。\n\n\n五、在 FastAPI 中使用连接池执行 SQL接下来我们在 main.py 中：\n\n初始化应用；\n把连接池挂载到应用上；\n通过依赖注入获取连接；\n写几个简单的接口做演示。\n\n# main.pyfrom typing import Generator, Listfrom fastapi import Depends, FastAPIfrom db import init_app, mysql_poolapp = FastAPI(title=&quot;FastAPI MySQL Pool Demo&quot;)init_app(app)def get_db_conn() -&gt; Generator:    &quot;&quot;&quot;FastAPI 依赖：从连接池获取一个连接。&quot;&quot;&quot;    with mysql_pool.connection() as conn:        yield conn@app.get(&quot;/users&quot;)def list_users(conn=Depends(get_db_conn)) -&gt; List[dict]:    &quot;&quot;&quot;查询用户列表，演示 SELECT。&quot;&quot;&quot;    with conn.cursor() as cursor:        sql = &quot;SELECT id, username, email FROM users ORDER BY id DESC LIMIT 20&quot;        cursor.execute(sql)        rows = cursor.fetchall()    # pymysql 默认返回 tuple，可以配置 cursorclass=DictCursor 直接返回 dict    # 这里演示手动转换    column_names = [desc[0] for desc in cursor.description]    return [dict(zip(column_names, row)) for row in rows]@app.post(&quot;/users&quot;)def create_user(username: str, email: str, conn=Depends(get_db_conn)) -&gt; dict:    &quot;&quot;&quot;新建用户，演示 INSERT。&quot;&quot;&quot;    with conn.cursor() as cursor:        sql = &quot;&quot;&quot;        INSERT INTO users (username, email)        VALUES (%s, %s)        &quot;&quot;&quot;        cursor.execute(sql, (username, email))        conn.commit()        user_id = cursor.lastrowid    return &#123;&quot;id&quot;: user_id, &quot;username&quot;: username, &quot;email&quot;: email&#125;\n\n几点说明：\n\n这里我们直接用 同步视图函数（def），用起来和传统 Flask、Django 中的写法类似；\n通过 Depends(get_db_conn)，把「从连接池获取连接」这件事交给 FastAPI 管理；\n所有 SQL 都是手写：\n完全不依赖 SQLModel &#x2F; ORM；\n需要什么 SQL 就写什么，DBA 给的脚本可以直接复用；\n\n\n使用参数化 SQL（%s + 参数元组）可以避免 SQL 注入风险。\n\n如果你希望 cursor.fetchall() 直接返回 dict，可以在创建连接池时配置：\nfrom pymysql.cursors import DictCursor# 在 MySQLPool.__init__ 中的 _pool_config 加一项：&quot;cursorclass&quot;: DictCursor,\n\n这样在接口中就可以直接：\nrows = cursor.fetchall()return list(rows)\n\n\n六、不用连接池时的常见写法对比很多入门教程里会给出类似这样的示例：\nimport pymysqlfrom fastapi import FastAPIapp = FastAPI()@app.get(&quot;/users&quot;)def list_users():    conn = pymysql.connect(        host=&quot;127.0.0.1&quot;,        port=3306,        user=&quot;root&quot;,        password=&quot;password&quot;,        database=&quot;mydb&quot;,        charset=&quot;utf8mb4&quot;,    )    try:        with conn.cursor() as cursor:            cursor.execute(&quot;SELECT id, username, email FROM users&quot;)            rows = cursor.fetchall()        conn.commit()        return rows    finally:        conn.close()\n\n这种写法：\n\n优点：入门门槛低，逻辑非常直观，适合 Demo 或脚本；\n缺点：\n每个请求都要 connect &#x2F; close，并发一上来，性能会明显下滑；\n一旦某个分支里忘记 close，连接泄漏就会变得非常难排查；\n连接数量完全依赖并发量，不可控。\n\n\n\n而使用 DBUtils 连接池的写法：\n\n连接在 应用启动时一次性建立 一部分；\n并发请求只是 从池子里借&#x2F;还连接，不会无限制创建新连接；\n通过 maxconnections 等参数，可以和 DBA 商量一个合理的连接数上限；\n代码中用 with 管理连接和游标，资源释放变得更安全、可控。\n\n\n七、实战中的一些优化建议最后再给几个在真实项目里经常会用到的小建议：\n\n和 DBA 对齐连接数配置：\n\n例如 MySQL 最大连接数是 500，那你的应用不要单实例就跑出 400 个连接；\n通常会预留一部分给排查&#x2F;备份&#x2F;其它服务使用。\n\n\n合理设置连接池参数：\n\nmincached：可以设置为 1～2，保证冷启动时就有可用连接；\nmaxcached &#x2F; maxconnections：结合 QPS 和 SQL 执行时间来调优；\nblocking=True：当连接用完时阻塞等待，而不是直接抛错，避免突发流量时崩掉。\n\n\n统一封装数据库访问层：\n\n不要在每个接口里都手写 cursor.execute + SQL 拼接；\n可以抽象出一层 repository 或 dao，接口层只关心业务对象即可。\n\n\n监控和日志：\n\n记录每条重要 SQL 的耗时、影响行数；\n对慢 SQL 做专门日志，方便后期优化。\n\n\n\n\n总结\n不用 SQLModel，也完全可以在 FastAPI 中优雅地直连 MySQL，关键是：\n使用 DBUtils 管理连接池；\n用 FastAPI 的依赖注入把「借连接&#x2F;还连接」这件事标准化。\n\n\n方案的核心是：\npymysql + DBUtils 连接池 + 手写 SQL&#96;，兼顾灵活性和性能；\n应用启动时初始化连接池，请求阶段按需借用连接，应用关闭时释放资源。\n\n\n真实项目里，建议再搭配一层轻量封装（DAO&#x2F;Repository），让业务代码只和“对象&#x2F;字典”打交道，把 SQL 细节收敛在数据访问层中。\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝你在测开与后端之路上越走越稳，越走越远。\n","tags":["FastAPI","数据库","连接池","MySQL","DBUtils","后端开发"]},{"title":"No.167-python开发命令行工具argparse中Sub-commands和Argument-groups有什么区别使用场景是什么","url":"/2025/12/22/No-167-python%E5%BC%80%E5%8F%91%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7argparse%E4%B8%ADSub-commands%E5%92%8CArgument-groups%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%E6%98%AF%E4%BB%80%E4%B9%88/","content":"导读在使用 Python 的 argparse 模块开发命令行工具时，我们经常会遇到这样的场景：\n\n工具功能越来越多，参数也越来越多，所有参数混在一起看起来很乱；\n想要实现类似 git commit、git push 这样的子命令功能；\n希望将相关的参数分组显示，让帮助信息更清晰。\n\n这时候，argparse 提供了两个看起来很相似的功能：Sub-commands（子命令） 和 Argument-groups（参数组）。\n很多同学会疑惑：这两个功能有什么区别？什么时候用哪个？\n这篇文章我们就来彻底搞懂这两个概念，让你在开发命令行工具时不再纠结。\n\n一、什么是 Sub-commands（子命令）？Sub-commands 就像 git 命令那样，一个主命令下可以有多个子命令，每个子命令有自己独立的参数。\n典型例子# git 就是典型的子命令模式git commit -m &quot;message&quot;git push origin maingit pull origin main\n\n每个子命令（commit、push、pull）都是独立的，有自己的参数和逻辑。\n代码示例import argparsedef main():    parser = argparse.ArgumentParser(description=&#x27;文件管理工具&#x27;)    subparsers = parser.add_subparsers(dest=&#x27;command&#x27;, help=&#x27;可用命令&#x27;)        # 创建 upload 子命令    upload_parser = subparsers.add_parser(&#x27;upload&#x27;, help=&#x27;上传文件&#x27;)    upload_parser.add_argument(&#x27;--file&#x27;, required=True, help=&#x27;要上传的文件路径&#x27;)    upload_parser.add_argument(&#x27;--bucket&#x27;, help=&#x27;存储桶名称&#x27;)        # 创建 download 子命令    download_parser = subparsers.add_parser(&#x27;download&#x27;, help=&#x27;下载文件&#x27;)    download_parser.add_argument(&#x27;--file&#x27;, required=True, help=&#x27;要下载的文件名&#x27;)    download_parser.add_argument(&#x27;--output&#x27;, help=&#x27;保存路径&#x27;)        args = parser.parse_args()        if args.command == &#x27;upload&#x27;:        print(f&quot;上传文件: &#123;args.file&#125; 到 &#123;args.bucket&#125;&quot;)    elif args.command == &#x27;download&#x27;:        print(f&quot;下载文件: &#123;args.file&#125; 到 &#123;args.output&#125;&quot;)if __name__ == &#x27;__main__&#x27;:    main()\n\n使用效果：\n# 上传文件python tool.py upload --file data.txt --bucket my-bucket# 下载文件python tool.py download --file data.txt --output ./local/\n\n\n二、什么是 Argument-groups（参数组）？Argument-groups 是用来组织和管理参数的，它不会改变命令的结构，只是把相关的参数分组显示，让帮助信息更清晰。\n典型场景当你有很多参数时，可以把它们按功能分组：\n# 所有参数都在一个命令下，但分组显示python tool.py --input file.txt --output dir/ --verbose --debug\n\n代码示例import argparsedef main():    parser = argparse.ArgumentParser(description=&#x27;数据处理工具&#x27;)        # 创建参数组    input_group = parser.add_argument_group(&#x27;输入选项&#x27;)    input_group.add_argument(&#x27;--input&#x27;, required=True, help=&#x27;输入文件路径&#x27;)    input_group.add_argument(&#x27;--format&#x27;, choices=[&#x27;json&#x27;, &#x27;csv&#x27;], help=&#x27;输入格式&#x27;)        output_group = parser.add_argument_group(&#x27;输出选项&#x27;)    output_group.add_argument(&#x27;--output&#x27;, required=True, help=&#x27;输出目录&#x27;)    output_group.add_argument(&#x27;--overwrite&#x27;, action=&#x27;store_true&#x27;, help=&#x27;是否覆盖已存在文件&#x27;)        debug_group = parser.add_argument_group(&#x27;调试选项&#x27;)    debug_group.add_argument(&#x27;--verbose&#x27;, action=&#x27;store_true&#x27;, help=&#x27;详细输出&#x27;)    debug_group.add_argument(&#x27;--debug&#x27;, action=&#x27;store_true&#x27;, help=&#x27;调试模式&#x27;)        args = parser.parse_args()    print(f&quot;处理文件: &#123;args.input&#125; -&gt; &#123;args.output&#125;&quot;)if __name__ == &#x27;__main__&#x27;:    main()\n\n使用效果：\n# 查看帮助信息，参数会按组显示python tool.py --help# 输出：# 输入选项:#   --input INPUT        输入文件路径#   --format &#123;json,csv&#125;  输入格式## 输出选项:#   --output OUTPUT      输出目录#   --overwrite          是否覆盖已存在文件## 调试选项:#   --verbose            详细输出#   --debug              调试模式\n\n\n三、两者的核心区别1. 功能定位不同\n\n\n特性\nSub-commands\nArgument-groups\n\n\n\n作用\n创建多个独立的命令\n组织参数显示\n\n\n命令结构\n改变命令结构（主命令 + 子命令）\n不改变命令结构\n\n\n参数隔离\n每个子命令的参数完全独立\n所有参数都在同一命令下\n\n\n2. 使用场景不同Sub-commands 适用于：\n\n✅ 工具功能模块化，每个功能相对独立\n✅ 不同功能需要的参数差异很大\n✅ 希望命令结构清晰，类似 git、docker 这样的工具\n✅ 不同子命令可能有完全不同的逻辑\n\nArgument-groups 适用于：\n\n✅ 所有参数都属于同一个命令\n✅ 参数很多，需要分类展示让帮助信息更清晰\n✅ 参数之间有逻辑关联，但都在同一个操作下使用\n✅ 希望帮助信息更易读，但不需要改变命令结构\n\n3. 代码结构对比Sub-commands 结构：\nparser = argparse.ArgumentParser()subparsers = parser.add_subparsers()# 每个子命令都是独立的 parsercmd1_parser = subparsers.add_parser(&#x27;cmd1&#x27;)cmd1_parser.add_argument(&#x27;--arg1&#x27;)cmd2_parser = subparsers.add_parser(&#x27;cmd2&#x27;)cmd2_parser.add_argument(&#x27;--arg2&#x27;)\n\nArgument-groups 结构：\nparser = argparse.ArgumentParser()# 所有参数都在同一个 parser 下，只是分组显示group1 = parser.add_argument_group(&#x27;组1&#x27;)group1.add_argument(&#x27;--arg1&#x27;)group2 = parser.add_argument_group(&#x27;组2&#x27;)group2.add_argument(&#x27;--arg2&#x27;)\n\n\n四、实际应用场景举例场景 1：文件管理工具（适合 Sub-commands）import argparsedef main():    parser = argparse.ArgumentParser(description=&#x27;文件管理工具&#x27;)    subparsers = parser.add_subparsers(dest=&#x27;command&#x27;)        # upload 子命令    upload = subparsers.add_parser(&#x27;upload&#x27;, help=&#x27;上传文件&#x27;)    upload.add_argument(&#x27;file&#x27;, help=&#x27;文件路径&#x27;)    upload.add_argument(&#x27;--bucket&#x27;, required=True)        # download 子命令    download = subparsers.add_parser(&#x27;download&#x27;, help=&#x27;下载文件&#x27;)    download.add_argument(&#x27;file&#x27;, help=&#x27;文件名&#x27;)    download.add_argument(&#x27;--output&#x27;, default=&#x27;./&#x27;)        # delete 子命令    delete = subparsers.add_parser(&#x27;delete&#x27;, help=&#x27;删除文件&#x27;)    delete.add_argument(&#x27;file&#x27;, help=&#x27;文件名&#x27;)    delete.add_argument(&#x27;--force&#x27;, action=&#x27;store_true&#x27;)        args = parser.parse_args()        if args.command == &#x27;upload&#x27;:        handle_upload(args.file, args.bucket)    elif args.command == &#x27;download&#x27;:        handle_download(args.file, args.output)    elif args.command == &#x27;delete&#x27;:        handle_delete(args.file, args.force)if __name__ == &#x27;__main__&#x27;:    main()\n\n使用：\npython tool.py upload data.txt --bucket my-bucketpython tool.py download data.txt --output ./files/python tool.py delete data.txt --force\n\n场景 2：数据处理工具（适合 Argument-groups）import argparsedef main():    parser = argparse.ArgumentParser(description=&#x27;数据处理工具&#x27;)        # 输入参数组    input_group = parser.add_argument_group(&#x27;输入配置&#x27;)    input_group.add_argument(&#x27;--input-file&#x27;, required=True, help=&#x27;输入文件&#x27;)    input_group.add_argument(&#x27;--input-format&#x27;, choices=[&#x27;json&#x27;, &#x27;csv&#x27;, &#x27;xml&#x27;])    input_group.add_argument(&#x27;--encoding&#x27;, default=&#x27;utf-8&#x27;)        # 处理参数组    process_group = parser.add_argument_group(&#x27;处理配置&#x27;)    process_group.add_argument(&#x27;--filter&#x27;, help=&#x27;过滤条件&#x27;)    process_group.add_argument(&#x27;--sort&#x27;, help=&#x27;排序字段&#x27;)    process_group.add_argument(&#x27;--limit&#x27;, type=int, help=&#x27;限制条数&#x27;)        # 输出参数组    output_group = parser.add_argument_group(&#x27;输出配置&#x27;)    output_group.add_argument(&#x27;--output-file&#x27;, required=True)    output_group.add_argument(&#x27;--output-format&#x27;, choices=[&#x27;json&#x27;, &#x27;csv&#x27;])    output_group.add_argument(&#x27;--pretty&#x27;, action=&#x27;store_true&#x27;)        args = parser.parse_args()    process_data(args)if __name__ == &#x27;__main__&#x27;:    main()\n\n使用：\npython tool.py \\  --input-file data.csv --input-format csv \\  --filter &quot;age &gt; 18&quot; --sort name --limit 100 \\  --output-file result.json --output-format json --pretty\n\n\n五、可以同时使用吗？可以！ 两者并不冲突，可以在子命令内部再使用参数组。\nimport argparsedef main():    parser = argparse.ArgumentParser(description=&#x27;高级工具&#x27;)    subparsers = parser.add_subparsers(dest=&#x27;command&#x27;)        # process 子命令，内部使用参数组    process_parser = subparsers.add_parser(&#x27;process&#x27;, help=&#x27;处理数据&#x27;)        input_group = process_parser.add_argument_group(&#x27;输入选项&#x27;)    input_group.add_argument(&#x27;--input&#x27;, required=True)    input_group.add_argument(&#x27;--format&#x27;, choices=[&#x27;json&#x27;, &#x27;csv&#x27;])        output_group = process_parser.add_argument_group(&#x27;输出选项&#x27;)    output_group.add_argument(&#x27;--output&#x27;, required=True)    output_group.add_argument(&#x27;--overwrite&#x27;, action=&#x27;store_true&#x27;)        args = parser.parse_args()    # ...if __name__ == &#x27;__main__&#x27;:    main()\n\n\n总结核心要点\nSub-commands（子命令）：\n\n用于创建多个独立的命令\n改变命令结构：主命令 子命令 [参数]\n适合功能模块化、参数差异大的场景\n典型例子：git commit、docker run\n\n\nArgument-groups（参数组）：\n\n用于组织和管理参数显示\n不改变命令结构，所有参数在同一命令下\n适合参数多、需要分类展示的场景\n主要作用是让帮助信息更清晰\n\n\n选择建议：\n\n功能独立、参数差异大 → 用 Sub-commands\n参数多、需要分类展示 → 用 Argument-groups\n两者可以结合使用\n\n\n\n快速决策树需要多个独立命令？├─ 是 → 使用 Sub-commands└─ 否 → 参数很多需要分组显示？    ├─ 是 → 使用 Argument-groups    └─ 否 → 直接用普通参数即可\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝你在测开与后端之路上越走越稳，越走越远。\n","tags":["后端开发","Python","argparse","命令行工具"]},{"title":"No.168-fastapi中OpenAPI-`Webhooks`怎么做","url":"/2025/12/28/No-168-fastapi%E4%B8%ADOpenAPI-Webhooks%E6%80%8E%E4%B9%88%E5%81%9A/","content":"导读大家好！今天来聊聊 FastAPI 中的 OpenAPI Webhooks。如果你正在开发需要向第三方推送消息的服务，比如订单状态变更、用户注册成功等场景，那 Webhooks 绝对是你的好帮手。\n什么是 Webhooks？简单理解就是”反向 API”：不是别人调你，而是你主动推送消息给别人。就像外卖小哥给你打电话通知”你的外卖到了”一样。\n方案为什么需要 Webhooks？想象一下这个场景：用户在你的平台上完成了支付，你需要立即通知第三方系统更新订单状态。如果用传统的 API，第三方需要不停地轮询你的接口：”订单支付了吗？”、”订单支付了吗？”……这样既浪费资源，实时性也差。\n而 Webhooks 则是”主动推送”模式：支付成功了？好，我马上通知你！这样既高效又及时。\nFastAPI 中如何定义 Webhooks？FastAPI 提供了非常优雅的方式来定义和文档化 Webhooks。让我们看一个实际例子：\nfrom fastapi import FastAPIfrom pydantic import BaseModelfrom datetime import datetimeapp = FastAPI()# 定义 Webhook 的数据模型class OrderStatus(BaseModel):    order_id: str    status: str  # &quot;paid&quot;, &quot;shipped&quot;, &quot;completed&quot; 等    amount: float    timestamp: datetime# 定义 Webhook 事件@app.Webhooks.post(&quot;order-status-changed&quot;)def order_status_changed(body: OrderStatus):    &quot;&quot;&quot;    当订单状态发生变化时，系统会向注册的 URL 发送 POST 请求。        实际应用中，你需要：    1. 让第三方系统注册他们的 Webhook URL    2. 在订单状态变更时，调用 httpx 向这些 URL 发送请求    &quot;&quot;&quot;    pass\n\n看到了吗？定义方式和普通路由几乎一样，只是用 app.Webhooks.post() 替代了 app.post()。\n实际使用场景示例让我们看一个完整的例子：电商平台的订单通知系统。\n第一步：定义 Webhook\nfrom fastapi import FastAPIfrom pydantic import BaseModelimport httpxapp = FastAPI()class OrderNotification(BaseModel):    order_id: str    user_id: str    total_amount: float    status: str    created_at: str@app.Webhooks.post(&quot;order-created&quot;)def order_created(body: OrderNotification):    &quot;&quot;&quot;新订单创建时的 Webhook&quot;&quot;&quot;    pass@app.Webhooks.post(&quot;order-paid&quot;)def order_paid(body: OrderNotification):    &quot;&quot;&quot;订单支付成功时的 Webhook&quot;&quot;&quot;    pass\n\n第二步：实现发送逻辑\n# webhook_sender.pyimport httpxfrom typing import List# 存储已注册的 Webhook URL（实际应用中应该存在数据库）registered_Webhooks = &#123;    &quot;order-created&quot;: [        &quot;https://partner1.com/webhook/orders&quot;,        &quot;https://partner2.com/webhook/notify&quot;    ],    &quot;order-paid&quot;: [        &quot;https://crm-system.com/webhook/order-payment&quot;    ]&#125;async def send_webhook(webhook_name: str, data: dict):    &quot;&quot;&quot;发送 Webhook 请求&quot;&quot;&quot;    urls = registered_Webhooks.get(webhook_name, [])        async with httpx.AsyncClient() as client:        for url in urls:            try:                response = await client.post(url, json=data, timeout=5.0)                print(f&quot;Webhook sent to &#123;url&#125;: &#123;response.status_code&#125;&quot;)            except Exception as e:                print(f&quot;Failed to send webhook to &#123;url&#125;: &#123;e&#125;&quot;)# 在业务代码中使用async def create_order(order_data: dict):    # ... 创建订单的业务逻辑 ...        # 订单创建成功后，发送 Webhook    await send_webhook(&quot;order-created&quot;, &#123;        &quot;order_id&quot;: order_data[&quot;order_id&quot;],        &quot;user_id&quot;: order_data[&quot;user_id&quot;],        &quot;total_amount&quot;: order_data[&quot;amount&quot;],        &quot;status&quot;: &quot;created&quot;,        &quot;created_at&quot;: datetime.now().isoformat()    &#125;)\n\n自动生成 API 文档FastAPI 最棒的地方在于，它会把你的 Webhooks 自动加入到 OpenAPI 文档中。启动应用后访问 http://127.0.0.1:8000/docs，你就能看到：\n\nWebhook 的名称\n请求体的数据结构\n字段说明和类型\n\n这样，第三方系统开发人员就能清楚地知道应该如何处理你发送的 Webhook 数据了！\n注意事项\n错误处理：Webhook 接收方可能暂时不可用，要做好重试机制和超时处理\n安全性：建议添加签名验证，确保 Webhook 请求来自你的系统\n幂等性：接收方应该能够安全地处理重复的 Webhook 请求\n\n# 添加签名验证的示例import hmacimport hashlibdef generate_signature(secret: str, payload: str) -&gt; str:    &quot;&quot;&quot;生成 Webhook 签名&quot;&quot;&quot;    return hmac.new(        secret.encode(),        payload.encode(),        hashlib.sha256    ).hexdigest()# 发送时添加签名头headers = &#123;    &quot;X-Webhook-Signature&quot;: generate_signature(secret_key, json.dumps(data))&#125;\n\n总结FastAPI 的 Webhooks 功能让”主动推送消息”变得简单优雅。通过 app.Webhooks.post() 定义事件，配合 Pydantic 模型定义数据结构，就能生成清晰的 API 文档。\n无论你是要通知第三方系统订单状态，还是推送用户注册事件，Webhooks 都是最佳选择。记住要做好错误处理和安全性验证，这样你的系统就能稳定可靠地运行了！\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝你在测开与后端之路上越走越稳，越走越远。\n"},{"title":"FastAPI中如何实现接口限流","url":"/2026/01/28/No-169-fastapi%E4%B8%AD%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%8E%A5%E5%8F%A3%E9%99%90%E6%B5%81/","content":"导读在 fastapi 项目中，接口限流是一个非常重要的话题。\n想象一下，如果没有限流，一个恶意用户可以在短时间内发起成千上万次请求，把你的服务打垮。或者你的某个不小心写了死循环的接口，把数据库连接池耗尽。\n这篇文章将介绍几种在 fastapi 中实现接口限流的方法。\n什么是接口限流？接口限流就是限制客户端在单位时间内可以发起的请求次数。常见的限流策略包括：\n\n固定窗口算法：在固定时间窗口内限制请求次数\n滑动窗口算法：更精确的时间窗口控制\n令牌桶算法：以固定速率产生令牌，请求消耗令牌\n漏桶算法：以固定速率处理请求\n\n方法1：使用 slowapi（推荐）slowapi 是一个专门为 FastAPI 设计的限流库，简单易用。\n安装：\npip install slowapi\n\n基础用法：\nfrom fastapi import FastAPI, Requestfrom slowapi import Limiter, _rate_limit_exceeded_handlerfrom slowapi.util import get_remote_addressfrom slowapi.errors import RateLimitExceededapp = FastAPI()# 初始化限流器limiter = Limiter(key_func=get_remote_address)app.state.limiter = limiterapp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)@app.get(&quot;/api/test&quot;)@limiter.limit(&quot;5/minute&quot;)  # 每分钟最多5次请求async def test_endpoint(request: Request):    return &#123;&quot;message&quot;: &quot;Hello&quot;&#125;\n\n说明：\n\nkey_func=get_remote_address 表示按 IP 地址限流\n@limiter.limit(&quot;5/minute&quot;) 表示每分钟最多5次请求\n超过限制时自动返回 429 状态码\n\n按用户ID限流：\nfrom fastapi import Depends, Requestfrom slowapi import Limiterdef get_user_id(request: Request):    # 从JWT token或其他方式获取用户ID    user_id = request.headers.get(&quot;X-User-ID&quot;, &quot;anonymous&quot;)    return user_idlimiter = Limiter(key_func=get_user_id)@app.get(&quot;/api/user-info&quot;)@limiter.limit(&quot;100/hour&quot;)  # 每小时最多100次请求async def user_info(request: Request):    return &#123;&quot;user_id&quot;: get_user_id(request)&#125;\n\n方法2：使用 fastapi-limiter另一个流行的限流库是 fastapi-limiter。\n安装：\npip install fastapi-limiter\n\n使用 Redis 作为存储：\nfrom fastapi import FastAPI, Depends, Requestfrom fastapi_limiter import FastAPILimiterfrom fastapi_limiter.depends import RateLimiterimport redisapp = FastAPI()# 初始化Redis连接@app.on_event(&quot;startup&quot;)async def startup():    redis_connection = redis.from_url(&quot;redis://localhost:6379&quot;)    await FastAPILimiter.init(redis=redis_connection)@app.get(&quot;/limited&quot;)@RateLimiter(times=2, seconds=5)  # 5秒内最多2次请求async def limited_route(request: Request):    return &#123;&quot;message&quot;: &quot;success&quot;&#125;\n\n说明：\n\n使用 Redis 可以在多实例环境下共享限流状态\ntimes=2, seconds=5 表示5秒内最多2次请求\n\n方法3：自定义基于内存的限流如果不想引入额外依赖，可以自己实现简单的限流器：\nfrom fastapi import FastAPI, Request, HTTPExceptionfrom collections import defaultdictfrom datetime import datetime, timedeltaimport asyncioapp = FastAPI()# 存储请求记录：&#123;ip: [(timestamp1, timestamp2, ...)]&#125;request_records = defaultdict(list)lock = asyncio.Lock()async def check_rate_limit(request: Request, max_requests: int = 10, window_seconds: int = 60):    &quot;&quot;&quot;检查请求是否超过限流&quot;&quot;&quot;    ip = request.client.host    now = datetime.now()    window_start = now - timedelta(seconds=window_seconds)    async with lock:        # 清理过期的记录        request_records[ip] = [            ts for ts in request_records[ip] if ts &gt; window_start        ]        # 检查是否超过限制        if len(request_records[ip]) &gt;= max_requests:            raise HTTPException(                status_code=429,                detail=f&quot;Rate limit exceeded. Try again later.&quot;            )        # 记录当前请求        request_records[ip].append(now)@app.get(&quot;/api/data&quot;)async def get_data(request: Request):    await check_rate_limit(request, max_requests=5, window_seconds=60)    return &#123;&quot;data&quot;: &quot;some data&quot;&#125;\n\n说明：\n\n使用字典存储每个IP的请求时间戳\n每次请求前清理过期的记录\n达到上限时抛出 429 异常\n使用异步锁避免并发问题\n\n方法4：使用装饰器类实现更优雅的实现方式是使用装饰器类：\nfrom functools import wrapsfrom fastapi import HTTPException, Requestimport timefrom collections import defaultdictclass RateLimiter:    def __init__(self, max_calls: int, time_window: int):        self.max_calls = max_calls        self.time_window = time_window        self.calls = defaultdict(list)    def __call__(self, func):        @wraps(func)        async def wrapper(request: Request, *args, **kwargs):            ip = request.client.host            current_time = time.time()            # 清理过期的调用记录            self.calls[ip] = [                t for t in self.calls[ip]                if current_time - t &lt; self.time_window            ]            # 检查是否超过限制            if len(self.calls[ip]) &gt;= self.max_calls:                raise HTTPException(                    status_code=429,                    detail=f&quot;Rate limit: &#123;self.max_calls&#125; calls per &#123;self.time_window&#125;s&quot;                )            # 记录这次调用            self.calls[ip].append(current_time)            return await func(request, *args, **kwargs)        return wrapper# 使用rate_limiter = RateLimiter(max_calls=10, time_window=60)@app.get(&quot;/api/limited-endpoint&quot;)@rate_limiterasync def limited_endpoint(request: Request):    return &#123;&quot;message&quot;: &quot;This endpoint is rate limited&quot;&#125;\n\n不同场景的限流策略全局限流@app.middleware(&quot;http&quot;)async def global_rate_limit(request: Request, call_next):    await check_rate_limit(request, max_requests=100, window_seconds=60)    response = await call_next(request)    return response\n\n路由级限流@app.get(&quot;/api/public&quot;)@limiter.limit(&quot;100/minute&quot;)  # 宽松限制async def public_api(request: Request):    return &#123;&quot;message&quot;: &quot;public content&quot;&#125;@app.get(&quot;/api/premium&quot;)@limiter.limit(&quot;1000/minute&quot;)  # 严格限制async def premium_api(request: Request):    return &#123;&quot;message&quot;: &quot;premium content&quot;&#125;\n\n用户级限流（差异化）def get_user_tier(request: Request):    # 假设从token中获取用户等级    token = request.headers.get(&quot;Authorization&quot;, &quot;&quot;)    if &quot;vip&quot; in token:        return &quot;vip&quot;    elif &quot;premium&quot; in token:        return &quot;premium&quot;    return &quot;free&quot;@app.get(&quot;/api/service&quot;)async def service(request: Request):    tier = get_user_tier(request)    if tier == &quot;vip&quot;:        await check_rate_limit(request, max_requests=1000, window_seconds=60)    elif tier == &quot;premium&quot;:        await check_rate_limit(request, max_requests=100, window_seconds=60)    else:        await check_rate_limit(request, max_requests=10, window_seconds=60)    return &#123;&quot;tier&quot;: tier&#125;\n\n生产环境建议\n使用 Redis 作为限流存储：支持分布式环境，避免多实例不一致\n设置合理的限流参数：根据业务需求和服务器容量设置\n返回友好错误信息：让用户知道限制和重试时间\n添加监控：记录被限流的请求，分析是否存在异常行为\n考虑降级策略：在系统压力过大时自动收紧限流\n\n自定义错误响应：\nfrom fastapi.responses import JSONResponseclass RateLimitExceeded(HTTPException):    def __init__(self, retry_after: int):        super().__init__(            status_code=429,            detail=&quot;Too many requests&quot;,            headers=&#123;&quot;Retry-After&quot;: str(retry_after)&#125;        )# 在限流检查中使用raise RateLimitExceeded(retry_after=60)\n\n测试限流功能import asyncioimport httpxasync def test_rate_limit():    client = httpx.AsyncClient()    tasks = [client.get(&quot;http://localhost:8000/api/test&quot;) for _ in range(10)]    responses = await asyncio.gather(*tasks)    for i, resp in enumerate(responses):        print(f&quot;Request &#123;i+1&#125;: &#123;resp.status_code&#125;&quot;)        if resp.status_code == 429:            print(f&quot;  Rate limited: &#123;resp.json()&#125;&quot;)asyncio.run(test_rate_limit())\n\n总结\n简单场景：使用 slowapi 或 fastapi-limiter\n分布式环境：必须使用 Redis 作为限流存储\n自定义需求：可以自己实现限流逻辑\n生产环境：添加监控和降级策略\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi"]},{"title":"FastAPI中间件使用实践","url":"/2026/01/30/No-170-fastapi%E4%B8%AD%E9%97%B4%E4%BB%B6%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/","content":"导读在 fastapi 开发中，中间件是一个非常强大的工具。\n想象一下，中间件就像是一个收费站。所有的车辆（请求）在进入高速公路（你的业务逻辑）之前，都要经过这个收费站。收费站可以检查车辆是否符合规定，记录车辆信息，甚至直接拦截某些车辆。\n这篇文章将介绍 FastAPI 中间件的使用场景、实现方式和最佳实践。\n什么是中间件？中间件是一个函数，它会在每个请求到达你的路由处理函数之前执行，在响应返回给客户端之前再次执行。中间件的典型执行流程：\n\n接收请求\n执行中间件代码（前置处理）\n调用实际的路由处理函数\n执行中间件代码（后置处理）\n返回响应\n\n基础用法创建简单中间件from fastapi import FastAPI, Requestapp = FastAPI()@app.middleware(&quot;http&quot;)async def log_requests(request: Request, call_next):    # 前置处理：请求到达路由之前    print(f&quot;请求方法: &#123;request.method&#125;, 路径: &#123;request.url.path&#125;&quot;)    # 调用下一个中间件或路由处理函数    response = await call_next(request)    # 后置处理：响应返回之前    print(f&quot;响应状态码: &#123;response.status_code&#125;&quot;)    return response@app.get(&quot;/&quot;)async def root():    return &#123;&quot;message&quot;: &quot;Hello World&quot;&#125;\n\n执行顺序：\n\nlog_requests 前置代码\n路由处理函数 root\nlog_requests 后置代码\nroot 返回响应\n\n计算请求处理时间import timefrom fastapi import FastAPI, Requestapp = FastAPI()@app.middleware(&quot;http&quot;)async def add_process_time_header(request: Request, call_next):    start_time = time.time()    response = await call_next(request)    process_time = time.time() - start_time    response.headers[&quot;X-Process-Time&quot;] = str(process_time)    return response\n\n这个中间件会在响应头中添加请求处理时间，方便性能监控。\nCORS 中间件跨域资源共享（CORS）是 Web 开发中常见的需求：\nfrom fastapi import FastAPIfrom fastapi.middleware.cors import CORSMiddlewareapp = FastAPI()app.add_middleware(    CORSMiddleware,    allow_origins=[&quot;http://localhost:3000&quot;, &quot;https://example.com&quot;],  # 允许的源    allow_credentials=True,  # 允许携带 cookies    allow_methods=[&quot;*&quot;],  # 允许所有 HTTP 方法    allow_headers=[&quot;*&quot;],  # 允许所有请求头    expose_headers=[&quot;X-Custom-Header&quot;],  # 暴露给前端的自定义响应头    max_age=600,  # 预检请求的缓存时间（秒）)\n\n注意：在生产环境中，应该明确指定 allow_origins，而不是使用 [&quot;*&quot;]。\n请求 ID 中间件为每个请求生成唯一标识，方便日志追踪：\nimport uuidfrom fastapi import FastAPI, Requestfrom starlette.middleware.base import BaseHTTPMiddlewarefrom starlette.types import ASGIAppclass RequestIDMiddleware(BaseHTTPMiddleware):    def __init__(self, app: ASGIApp):        super().__init__(app)    async def dispatch(self, request: Request, call_next):        # 生成或获取请求 ID        request_id = request.headers.get(&quot;X-Request-ID&quot;, str(uuid.uuid4()))        # 添加到请求状态        request.state.request_id = request_id        response = await call_next(request)        # 在响应头中返回请求 ID        response.headers[&quot;X-Request-ID&quot;] = request_id        return responseapp = FastAPI()app.add_middleware(RequestIDMiddleware)@app.get(&quot;/&quot;)async def root(request: Request):    # 在路由中使用请求 ID    return &#123;&quot;request_id&quot;: request.state.request_id&#125;\n\n认证中间件实现基础的认证逻辑：\nfrom fastapi import FastAPI, Request, HTTPException, Dependsapp = FastAPI()@app.middleware(&quot;http&quot;)async def verify_token(request: Request, call_next):    # 跳过某些路径的验证    if request.url.path in [&quot;/docs&quot;, &quot;/openapi.json&quot;, &quot;/health&quot;]:        return await call_next(request)    # 获取 token    token = request.headers.get(&quot;Authorization&quot;)    if not token:        raise HTTPException(status_code=401, detail=&quot;未提供认证令牌&quot;)    # 简单验证（实际应该验证 JWT 或查询数据库）    if not token.startswith(&quot;Bearer &quot;):        raise HTTPException(status_code=401, detail=&quot;无效的令牌格式&quot;)    # 可以将用户信息存入 request.state 供后续使用    request.state.user = &quot;user123&quot;  # 实际应该解析 token 获取用户信息    return await call_next(request)@app.get(&quot;/protected&quot;)async def protected(request: Request):    # 使用 request.state 中的用户信息    return &#123;&quot;message&quot;: &quot;这是一个受保护的接口&quot;, &quot;user&quot;: request.state.user&#125;\n\n日志中间件更完善的日志记录：\nimport loggingimport jsonfrom datetime import datetimefrom fastapi import FastAPI, Request# 配置日志logging.basicConfig(    level=logging.INFO,    format=&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;)logger = logging.getLogger(&quot;api&quot;)app = FastAPI()@app.middleware(&quot;http&quot;)async def log_requests(request: Request, call_next):    start_time = datetime.now()    # 记录请求信息    log_data = &#123;        &quot;method&quot;: request.method,        &quot;path&quot;: request.url.path,        &quot;client_ip&quot;: request.client.host,        &quot;user_agent&quot;: request.headers.get(&quot;user-agent&quot;),    &#125;    response = await call_next(request)    # 计算处理时间    process_time = (datetime.now() - start_time).total_seconds()    # 更新日志数据    log_data.update(&#123;        &quot;status_code&quot;: response.status_code,        &quot;process_time_ms&quot;: round(process_time * 1000, 2),    &#125;)    # 记录日志    logger.info(json.dumps(log_data))    return response\n\n异常捕获中间件统一处理异常：\nfrom fastapi import FastAPI, Request, HTTPExceptionfrom fastapi.responses import JSONResponseimport tracebackapp = FastAPI()class ExceptionHandlerMiddleware:    def __init__(self, app):        self.app = app    async def __call__(self, scope, receive, send):        async def send_wrapper(message):            if message[&quot;type&quot;] == &quot;http.response.start&quot;:                # 可以在这里修改响应状态码                pass            await send(message)        try:            await self.app(scope, receive, send_wrapper)        except Exception as e:            # 统一异常处理            error_response = JSONResponse(                status_code=500,                content=&#123;                    &quot;error&quot;: &quot;Internal Server Error&quot;,                    &quot;message&quot;: str(e),                    &quot;detail&quot;: traceback.format_exc() if app.debug else None,                &#125;            )            await error_response(scope, receive, send)# 注意：FastAPI 有内置的异常处理机制，通常使用 exception_handler 更合适# 推荐方式：使用全局异常处理器@app.exception_handler(Exception)async def global_exception_handler(request: Request, exc: Exception):    return JSONResponse(        status_code=500,        content=&#123;            &quot;error&quot;: &quot;Internal Server Error&quot;,            &quot;message&quot;: str(exc),        &#125;    )@app.exception_handler(HTTPException)async def http_exception_handler(request: Request, exc: HTTPException):    return JSONResponse(        status_code=exc.status_code,        content=&#123;            &quot;error&quot;: exc.detail,            &quot;status_code&quot;: exc.status_code,        &#125;    )\n\n中间件执行顺序中间件的执行顺序很重要。FastAPI 按照添加的顺序执行中间件：\nfrom fastapi import FastAPI, Requestapp = FastAPI()@app.middleware(&quot;http&quot;)async def middleware1(request: Request, call_next):    print(&quot;中间件1：前置&quot;)    response = await call_next(request)    print(&quot;中间件1：后置&quot;)    return response@app.middleware(&quot;http&quot;)async def middleware2(request: Request, call_next):    print(&quot;中间件2：前置&quot;)    response = await call_next(request)    print(&quot;中间件2：后置&quot;)    return response@app.get(&quot;/&quot;)async def root():    print(&quot;路由处理&quot;)    return &#123;&quot;message&quot;: &quot;Hello&quot;&#125;# 执行顺序：# 中间件1：前置# 中间件2：前置# 路由处理# 中间件2：后置# 中间件1：后置\n\n跳过中间件有时需要为某些路由跳过中间件：\nfrom fastapi import FastAPI, Requestapp = FastAPI()# 定义不需要认证的路径PUBLIC_PATHS = &#123;    &quot;/&quot;,    &quot;/health&quot;,    &quot;/docs&quot;,    &quot;/openapi.json&quot;,&#125;@app.middleware(&quot;http&quot;)async def auth_middleware(request: Request, call_next):    # 跳过公共路径    if request.url.path in PUBLIC_PATHS:        return await call_next(request)    # 执行认证逻辑    token = request.headers.get(&quot;Authorization&quot;)    if not token:        return JSONResponse(status_code=401, content=&#123;&quot;error&quot;: &quot;Unauthorized&quot;&#125;)    return await call_next(request)\n\n或者使用路由分组：\nfrom fastapi import FastAPI, Requestfrom fastapi.responses import JSONResponseapp = FastAPI()public_router = APIRouter()protected_router = APIRouter()# 认证中间件只应用到 protected_router@protected_router.middleware(&quot;http&quot;)async def auth_middleware(request: Request, call_next):    token = request.headers.get(&quot;Authorization&quot;)    if not token:        raise HTTPException(status_code=401, detail=&quot;Unauthorized&quot;)    return await call_next(request)@public_router.get(&quot;/health&quot;)async def health():    return &#123;&quot;status&quot;: &quot;ok&quot;&#125;@protected_router.get(&quot;/user&quot;)async def get_user():    return &#123;&quot;user&quot;: &quot;info&quot;&#125;app.include_router(public_router)app.include_router(protected_router, prefix=&quot;/api&quot;, dependencies=[Depends(verify_token)])\n\n中间件与依赖注入的区别中间件和依赖注入有些相似，但适用场景不同：\n中间件的特点：\n\n对所有请求生效（除非明确跳过）\n适合全局功能（日志、CORS、全局认证）\n可以修改请求和响应\n执行顺序固定\n\n依赖注入的特点：\n\n更灵活，可以按需使用\n适合特定的路由或参数\n适合资源管理（数据库连接、用户权限检查）\n可以传递参数\n\n# 中间件示例@app.middleware(&quot;http&quot;)async def global_middleware(request: Request, call_next):    # 对所有请求生效    return await call_next(request)# 依赖注入示例async def get_current_user(token: str = Header(...)):    # 只在需要的路由中使用    return user@app.get(&quot;/profile&quot;, dependencies=[Depends(get_current_user)])async def profile():    return &#123;&quot;profile&quot;: &quot;data&quot;&#125;\n\n常见中间件库GZip 压缩from fastapi import FastAPIfrom fastapi.middleware.gzip import GZipMiddlewareapp = FastAPI()app.add_middleware(GZipMiddleware, minimum_size=1000)  # 大于 1KB 的响应才压缩\n\nHTTPS 重定向from fastapi import FastAPI, Requestfrom fastapi.responses import RedirectResponseapp = FastAPI()@app.middleware(&quot;http&quot;)async def https_redirect(request: Request, call_next):    # 在生产环境中应该由反向代理（如 Nginx）处理    if request.url.scheme != &quot;https&quot; and request.client.host != &quot;127.0.0.1&quot;:        url = request.url.replace(scheme=&quot;https&quot;)        return RedirectResponse(url=str(url))    return await call_next(request)\n\n性能考虑中间件会增加每个请求的处理开销，应该注意：\nimport time@app.middleware(&quot;http&quot;)async def performance_monitor(request: Request, call_next):    start_time = time.perf_counter()    response = await call_next(request)    process_time = time.perf_counter() - start_time    # 性能敏感：只记录慢请求    if process_time &gt; 0.5:  # 超过 500ms 才记录        logger.warning(f&quot;慢请求: &#123;request.url.path&#125; 耗时 &#123;process_time:.3f&#125;s&quot;)    return response\n\n生产环境建议\n使用专业的日志库（如 structlog）而不是 print\n将请求 ID 记录到所有日志中，方便追踪\n在生产环境中不暴露详细错误信息\n考虑使用 Sentry 等错误追踪服务\n监控慢请求和异常\n\n完整的中间件配置示例：\nfrom fastapi import FastAPI, Request, HTTPExceptionfrom fastapi.middleware.cors import CORSMiddlewarefrom fastapi.middleware.gzip import GZipMiddlewarefrom fastapi.responses import JSONResponseimport loggingimport uuidimport time# 配置日志logging.basicConfig(level=logging.INFO)logger = logging.getLogger(&quot;api&quot;)app = FastAPI()# CORS 中间件app.add_middleware(    CORSMiddleware,    allow_origins=[&quot;https://yourdomain.com&quot;],    allow_credentials=True,    allow_methods=[&quot;*&quot;],    allow_headers=[&quot;*&quot;],)# GZip 压缩app.add_middleware(GZipMiddleware, minimum_size=1000)# 请求 ID 中间件@app.middleware(&quot;http&quot;)async def request_id_middleware(request: Request, call_next):    request_id = request.headers.get(&quot;X-Request-ID&quot;, str(uuid.uuid4()))    request.state.request_id = request_id    response = await call_next(request)    response.headers[&quot;X-Request-ID&quot;] = request_id    return response# 日志中间件@app.middleware(&quot;http&quot;)async def logging_middleware(request: Request, call_next):    start_time = time.time()    response = await call_next(request)    process_time = time.time() - start_time    logger.info(        f&quot;Request: &#123;request.method&#125; &#123;request.url.path&#125; | &quot;        f&quot;Status: &#123;response.status_code&#125; | &quot;        f&quot;Time: &#123;process_time:.3f&#125;s | &quot;        f&quot;ID: &#123;request.state.request_id&#125;&quot;    )    return response# 全局异常处理@app.exception_handler(Exception)async def global_exception_handler(request: Request, exc: Exception):    logger.error(        f&quot;Error: &#123;str(exc)&#125; | &quot;        f&quot;Request: &#123;request.url.path&#125; | &quot;        f&quot;ID: &#123;request.state.request_id&#125;&quot;    )    return JSONResponse(        status_code=500,        content=&#123;&quot;error&quot;: &quot;Internal Server Error&quot;&#125;    )@app.get(&quot;/health&quot;)async def health():    return &#123;&quot;status&quot;: &quot;ok&quot;&#125;\n\n总结\n中间件适合全局功能：日志、认证、CORS、压缩\n注意中间件的执行顺序\n可以跳过特定路径的中间件\n中间件和依赖注入各有用途，合理选择\n生产环境要考虑性能和安全性\n\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝君在测开之路上越走越顺，越走越远。\n","tags":["fastapi","中间件"]},{"title":"No.171-FastAPI依赖注入系统详解","url":"/2026/02/27/No-171-fastapi%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E7%B3%BB%E7%BB%9F%E8%AF%A6%E8%A7%A3/","content":"导读在日常开发中，我们经常需要在多个接口中复用某些逻辑，比如数据库连接、用户认证、配置读取等。如果每个接口都重复写一遍这些代码，不仅繁琐，还容易出错。这时候，依赖注入就派上用场了。\n想象一下，你是一家餐厅的厨师。每天做饭时，你都需要用到刀具、砧板、调料等工具。如果每次做饭都要自己准备这些工具，那效率肯定很低。更聪明的做法是：餐厅统一管理这些工具，你需要什么，餐厅就给你什么。这就是依赖注入的核心思想。\nFastAPI 的依赖注入系统非常强大，它不仅支持简单的函数依赖，还支持类依赖、嵌套依赖、异步依赖等多种场景。今天我们就来深入探讨 FastAPI 的依赖注入系统，看看它如何让我们的代码更加简洁、可维护。\n什么是依赖注入依赖注入（Dependency Injection，简称 DI）是一种设计模式，它的核心思想是：将对象的创建和管理交给外部容器，而不是在对象内部自己创建。这样可以降低组件之间的耦合度，提高代码的可测试性和可维护性。\n在 FastAPI 中，依赖注入通过 Depends 类来实现。你可以在路径操作函数的参数中声明依赖，FastAPI 会自动解析并注入这些依赖。\n基础用法让我们从一个简单的例子开始：\nfrom fastapi import FastAPI, Dependsapp = FastAPI()# 定义一个依赖函数def get_token():    return &quot;secret-token-123&quot;# 在接口中使用依赖@app.get(&quot;/items/&quot;)def read_items(token: str = Depends(get_token)):    return &#123;&quot;token&quot;: token&#125;\n\n在这个例子中，get_token 函数是一个依赖，read_items 接口通过 Depends(get_token) 声明了对它的依赖。当请求到达时，FastAPI 会自动调用 get_token 函数，并将返回值注入到 token 参数中。\n依赖函数的参数依赖函数本身也可以有参数，这些参数会按照 FastAPI 的标准参数解析规则进行处理：\nfrom fastapi import FastAPI, Depends, Headerapp = FastAPI()def get_token(x_token: str = Header(...)):    return x_token@app.get(&quot;/items/&quot;)def read_items(token: str = Depends(get_token)):    return &#123;&quot;token&quot;: token&#125;\n\n在这个例子中，get_token 函数从请求头中获取 X-Token 字段，并将其作为依赖的返回值。\n类作为依赖除了函数，类也可以作为依赖。这在需要维护状态的情况下非常有用：\nfrom fastapi import FastAPI, Dependsapp = FastAPI()class CommonQueryParams:    def __init__(self, skip: int = 0, limit: int = 100):        self.skip = skip        self.limit = limit@app.get(&quot;/items/&quot;)def read_items(commons: CommonQueryParams = Depends(CommonQueryParams)):    response = &#123;&#125;    if commons.skip:        response.update(&#123;&quot;skip&quot;: commons.skip&#125;)    if commons.limit:        response.update(&#123;&quot;limit&quot;: commons.limit&#125;)    return response\n\nFastAPI 会自动解析类的构造函数参数，创建类的实例，并将其注入到路径操作函数中。\n使用 Annotated 简化依赖声明从 Python 3.9 开始，推荐使用 Annotated 来声明依赖：\nfrom typing import Annotatedfrom fastapi import FastAPI, Dependsapp = FastAPI()class CommonQueryParams:    def __init__(self, skip: int = 0, limit: int = 100):        self.skip = skip        self.limit = limit@app.get(&quot;/items/&quot;)def read_items(commons: Annotated[CommonQueryParams, Depends(CommonQueryParams)]):    return &#123;&quot;skip&quot;: commons.skip, &quot;limit&quot;: commons.limit&#125;\n\n这种方式更加清晰，并且可以在同一个参数上同时声明类型和依赖。\n依赖覆盖在测试场景中，我们经常需要覆盖某些依赖，使用测试数据而不是真实的依赖。FastAPI 提供了 app.dependency_overrides 来实现这个功能：\nfrom fastapi import FastAPI, Dependsapp = FastAPI()def get_token():    return &quot;real-token&quot;@app.get(&quot;/items/&quot;)def read_items(token: str = Depends(get_token)):    return &#123;&quot;token&quot;: token&#125;# 测试时覆盖依赖def test_get_items():    # 覆盖依赖    app.dependency_overrides[get_token] = lambda: &quot;test-token&quot;    # 调用测试    response = client.get(&quot;/items/&quot;)    assert response.json() == &#123;&quot;token&quot;: &quot;test-token&quot;&#125;    # 清除覆盖    app.dependency_overrides.clear()\n\n这种方式非常适合单元测试和集成测试，可以避免使用真实的数据库、外部 API 等资源。\n异步依赖FastAPI 的依赖系统完全支持异步操作。如果你的依赖需要执行异步操作（比如查询数据库），只需将依赖函数声明为 async 即可：\nfrom fastapi import FastAPI, Dependsfrom typing import AsyncGeneratorapp = FastAPI()async def get_db_connection():    # 模拟异步数据库连接    connection = &quot;db-connection&quot;    yield connection    # 清理资源    print(&quot;Closing database connection&quot;)@app.get(&quot;/items/&quot;)async def read_items(db: str = Depends(get_db_connection)):    return &#123;&quot;db&quot;: db&#125;\n\n在这个例子中，get_db_connection 是一个生成器函数，它在依赖注入时执行 yield 之前的代码，返回连接对象，在请求处理完成后执行 yield 之后的代码，用于清理资源。\n嵌套依赖依赖可以嵌套使用，一个依赖可以依赖于另一个依赖：\nfrom fastapi import FastAPI, Dependsapp = FastAPI()def query_extractor(q: str | None = None):    return qdef query_or_cookie_extractor(    q: str = Depends(query_extractor),    last_query: str | None = None):    if not q:        return last_query    return q@app.get(&quot;/items/&quot;)def read_query(    query_result: str = Depends(query_or_cookie_extractor)):    return &#123;&quot;query_result&quot;: query_result&#125;\n\n在这个例子中，query_or_cookie_extractor 依赖于 query_extractor，FastAPI 会自动解析整个依赖链。\n全局依赖有时候，我们需要对整个应用的所有接口应用某个依赖，比如全局的认证、日志记录等。FastAPI 允许在应用级别声明全局依赖：\nfrom fastapi import FastAPI, Depends, Headerapp = FastAPI()async def verify_token(x_token: str = Header(...)):    if x_token != &quot;fake-super-secret-token&quot;:        raise HTTPException(status_code=400, detail=&quot;X-Token header invalid&quot;)# 全局依赖app = FastAPI(dependencies=[Depends(verify_token)])@app.get(&quot;/items/&quot;)async def read_items():    return [&#123;&quot;item&quot;: &quot;Foo&quot;&#125;, &#123;&quot;item&quot;: &quot;Bar&quot;&#125;]\n\n这样，所有接口都会自动应用 verify_token 依赖，无需在每个接口中重复声明。\n实际应用场景数据库连接管理在实际项目中，数据库连接是最常见的依赖场景：\nfrom fastapi import FastAPI, Dependsfrom sqlalchemy.orm import Sessionfrom typing import Generatorapp = FastAPI()# 数据库连接池def get_db() -&gt; Generator[Session, None, None]:    db = SessionLocal()    try:        yield db    finally:        db.close()@app.get(&quot;/users/&#123;user_id&#125;&quot;)def read_user(user_id: int, db: Session = Depends(get_db)):    user = db.query(User).filter(User.id == user_id).first()    return user\n\n用户认证依赖注入也非常适合处理用户认证：\nfrom fastapi import FastAPI, Depends, HTTPException, Headerfrom typing import Optionalapp = FastAPI()def get_current_user(authorization: str = Header(...)):    # 解析 token 并获取用户信息    token = authorization.replace(&quot;Bearer &quot;, &quot;&quot;)    user = verify_token(token)    if not user:        raise HTTPException(status_code=401, detail=&quot;Invalid token&quot;)    return user@app.get(&quot;/users/me&quot;)def read_users_me(current_user: User = Depends(get_current_user)):    return current_user\n\n配置读取将配置读取逻辑封装成依赖，可以方便地在不同环境中切换配置：\nfrom fastapi import FastAPI, Dependsfrom pydantic import BaseSettingsclass Settings(BaseSettings):    app_name: str = &quot;My App&quot;    app_version: str = &quot;1.0.0&quot;    debug: bool = False    class Config:        env_file = &quot;.env&quot;def get_settings() -&gt; Settings:    return Settings()@app.get(&quot;/info&quot;)def get_app_info(settings: Settings = Depends(get_settings)):    return &#123;        &quot;app_name&quot;: settings.app_name,        &quot;app_version&quot;: settings.app_version,        &quot;debug&quot;: settings.debug    &#125;\n\n总结FastAPI 的依赖注入系统是一个非常强大且灵活的功能，它可以帮助我们：\n\n减少代码重复：将公共逻辑抽取成依赖，在多个接口中复用\n提高代码可测试性：通过依赖覆盖，方便地进行单元测试和集成测试\n降低耦合度：组件之间通过依赖接口交互，而不是直接依赖具体实现\n简化资源管理：使用生成器依赖，自动管理资源的创建和释放\n支持异步操作：完全支持异步依赖，适合现代异步应用\n\n在实际开发中，合理使用依赖注入可以让代码更加简洁、可维护，提高开发效率。\n最佳实践\n单一职责：每个依赖只负责一个功能，保持依赖的简洁性\n使用类型注解：充分利用 Python 的类型注解，让代码更加清晰\n善用生成器：对于需要资源清理的场景，使用生成器依赖\n合理分层：将依赖按照功能分层，避免依赖链过长\n编写测试：利用依赖覆盖，为每个依赖编写单元测试\n\n每日踩一坑，生活更轻松。\n本期分享就到这里啦，祝你在测开与后端之路上越走越稳，越走越远。\n","tags":["fastapi","依赖注入","python"]}]